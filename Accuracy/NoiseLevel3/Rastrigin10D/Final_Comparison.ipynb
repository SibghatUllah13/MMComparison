{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pyDOE\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import namedtuple\n",
    "from matplotlib import cm\n",
    "from scipy.stats import mannwhitneyu\n",
    "import cma\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pyDOE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats.distributions as dist\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.gaussian_process.kernels import DotProduct\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from collections import namedtuple\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from RBFN import RBFN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValueRange = namedtuple('ValueRange', ['min', 'max'])\n",
    "\n",
    "def determinerange(values):\n",
    "    \"\"\"Determine the range of values in each dimension\"\"\"\n",
    "    return ValueRange(np.min(values, axis=0), np.max(values, axis=0))\n",
    "\n",
    "\n",
    "def linearscaletransform(values, *, range_in=None, range_out=ValueRange(0, 1), scale_only=False):\n",
    "    \"\"\"Perform a scale transformation of `values`: [range_in] --> [range_out]\"\"\"\n",
    "\n",
    "    if range_in is None:\n",
    "        range_in = determinerange(values)\n",
    "    elif not isinstance(range_in, ValueRange):\n",
    "        range_in = ValueRange(*range_in)\n",
    "\n",
    "    if not isinstance(range_out, ValueRange):\n",
    "        range_out = ValueRange(*range_out)\n",
    "\n",
    "    scale_out = range_out.max - range_out.min\n",
    "    scale_in = range_in.max - range_in.min\n",
    "\n",
    "    if scale_only:\n",
    "        scaled_values = (values / scale_in) * scale_out\n",
    "    else:\n",
    "        scaled_values = (values - range_in.min) / scale_in\n",
    "        scaled_values = (scaled_values * scale_out) + range_out.min\n",
    "\n",
    "    return scaled_values\n",
    "\n",
    "\n",
    "''' Original Function for Optimization '''\n",
    "def rastrigin_10D(x):\n",
    "    x = list(x)\n",
    "    return sum([y**2 - 10*np.cos(2*math.pi*y) + (10*len(x)) for y in x])\n",
    "\n",
    "''' Latin HyperCube Sampling Design of Experiment '''\n",
    "def DOE(n_obs):\n",
    "    np.random.seed(0)\n",
    "    lhd = pyDOE.lhs(n=10, samples=n_obs, criterion='m')\n",
    "    X1,X2,X3,X4,X5,X6,X7,X8,X9,X10 = lhd[:,0],lhd[:,1],lhd[:,2],lhd[:,3],lhd[:,4],lhd[:,5], lhd[:,6],lhd[:,7],lhd[:,8],lhd[:,9]\n",
    "    return X1,X2,X3,X4,X5,X6,X7,X8,X9,X10\n",
    "\n",
    "\n",
    "'''Robust Regularization based on minimax Principle'''\n",
    "def robust_regularization(X):\n",
    "    x1,x2,x3,x4,x5,x6,x7,x8,x9,x10 = X\n",
    "    eps = np.linspace(-2.048,2.048,1000)\n",
    "    result = np.zeros(eps.shape[0])\n",
    "    for i in range(eps.shape[0]):\n",
    "        result[i]= rastrigin_10D(np.array([x1+eps[i],x2+eps[i],x3+eps[i],x4+eps[i],x5+eps[i],x6+eps[i],\n",
    "                                        x7+eps[i],x8+eps[i],x9+eps[i],x10+eps[i]]))\n",
    "    return np.max(result[i])\n",
    "\n",
    "''' Robustness based on a composite function of Mean and STd '''\n",
    "def composite_robustness(X):\n",
    "    w=1\n",
    "    x1,x2,x3,x4,x5,x6,x7,x8,x9,x10 = X\n",
    "    np.random.seed(0)\n",
    "    eps = np.random.normal(loc=0.0,scale=0.3413333333333333,size=10000)\n",
    "    sample_points = np.zeros(eps.shape[0])\n",
    "    for i in range(eps.shape[0]):\n",
    "        sample_points[i]= rastrigin_10D(np.array([x1+eps[i],x2+eps[i],x3+eps[i],x4+eps[i],x5+eps[i],x6+eps[i],\n",
    "                                        x7+eps[i],x8+eps[i],x9+eps[i],x10+eps[i]]))\n",
    "    sample_mean = np.mean(sample_points)\n",
    "    variance = np.square(sample_points-sample_mean)\n",
    "    std = np.sqrt(np.mean(variance))\n",
    "    std = np.sqrt(np.mean(variance))\n",
    "    return sample_mean + w * std\n",
    "\n",
    "''' Generate Training Data using LHD along side the Output of the Robust System'''\n",
    "def generate_training_data(n_obs):\n",
    "    X1,X2,X3,X4,X5,X6,X7,X8,X9,X10 = DOE(n_obs)\n",
    "    X1 = linearscaletransform(X1,range_out=(-5.12,5.12))\n",
    "    X2 = linearscaletransform(X2,range_out=(-5.12,5.12))\n",
    "    X3 = linearscaletransform(X3,range_out=(-5.12,5.12))\n",
    "    X4 = linearscaletransform(X4,range_out=(-5.12,5.12))\n",
    "    X5 = linearscaletransform(X5,range_out=(-5.12,5.12))\n",
    "    X6 = linearscaletransform(X6,range_out=(-5.12,5.12))\n",
    "    X7 = linearscaletransform(X7,range_out=(-5.12,5.12))\n",
    "    X8 = linearscaletransform(X8,range_out=(-5.12,5.12))\n",
    "    X9 = linearscaletransform(X9,range_out=(-5.12,5.12))\n",
    "    X10 = linearscaletransform(X10,range_out=(-5.12,5.12))\n",
    "    f_evaluation = np.zeros(X1.shape[0])\n",
    "    for i in range(X1.shape[0]):\n",
    "        f_evaluation [i] = rastrigin_10D(np.array([X1[i],X2[i],X3[i],X4[i],X5[i],X6[i],X7[i],X8[i],X9[i],X10[i]]))\n",
    "    f_original = np.zeros(X1.shape[0])\n",
    "    minimax_original = np.zeros(X1.shape[0])\n",
    "    composite_original = np.zeros(X1.shape[0])\n",
    "    for i in range(X1.shape[0]):\n",
    "        f_original[i] = rastrigin_10D(np.array([X1[i],X2[i],X3[i],X4[i],X5[i],X6[i],X7[i],X8[i],X9[i],X10[i]]))\n",
    "        minimax_original[i] = robust_regularization(np.array([X1[i],X2[i],X3[i],X4[i],X5[i],X6[i],X7[i],X8[i],X9[i],X10[i]]))\n",
    "        composite_original[i] = composite_robustness(np.array([X1[i],X2[i],X3[i],X4[i],X5[i],X6[i],X7[i],X8[i],X9[i],X10[i]]))\n",
    "    train = pd.DataFrame()\n",
    "    train['X1'] = pd.Series(X1)\n",
    "    train['X2'] = pd.Series(X2)\n",
    "    train['X3'] = pd.Series(X3)\n",
    "    train['X4'] = pd.Series(X4)\n",
    "    train['X5'] = pd.Series(X5)\n",
    "    train['X6'] = pd.Series(X6)\n",
    "    train['X7'] = pd.Series(X7)\n",
    "    train['X8'] = pd.Series(X8)\n",
    "    train['X9'] = pd.Series(X9)\n",
    "    train['X10'] = pd.Series(X10)\n",
    "    train['Y = F(X1,X2)'] = pd.Series(f_original)\n",
    "    train['Y = robust_regularization(X1,X2)'] = pd.Series(minimax_original)\n",
    "    train['Y = composite(X1,X2)'] = pd.Series(composite_original)\n",
    "    train.to_csv('Training_Data_Sets\\\\'+str(n_obs)+'Samples.csv')\n",
    "    return train\n",
    "\n",
    "''' Generate Test Data using LHD along side the Output of the Robust System'''\n",
    "def generate_test_data(n_obs):\n",
    "    test = pd.DataFrame()\n",
    "    X = pyDOE.lhs(n=10, samples=n_obs, criterion='m')\n",
    "    for i in range(X.shape[1]):\n",
    "        X[:,i] = linearscaletransform(X[:,i],range_out=(-5.12,5.12))\n",
    "        test['X'+str(i+1)] = pd.Series(X[:,i])\n",
    "    true_minimax = np.zeros(X.shape[0])\n",
    "    true_composite = np.zeros(X.shape[0])\n",
    "    for i in range(X.shape[0]):\n",
    "        true_minimax[i] = robust_regularization(X[i,:])\n",
    "        true_composite[i] = composite_robustness(X[i,:])\n",
    "    test ['True_Minimax'] = pd.Series(true_minimax)\n",
    "    test ['True_Composite'] = pd.Series(true_composite)\n",
    "    test.to_csv('Test_Data_Sets\\\\'+str(n_obs)+'Samples.csv')\n",
    "    return test\n",
    "\n",
    "\n",
    "\n",
    "''' Create Basis Functions '''\n",
    "def create_function_basis(x):\n",
    "    x = np.array(x)\n",
    "    y = np.zeros(len(x))\n",
    "    z = np.zeros(45)\n",
    "    for i in range(len(x)):\n",
    "        y[i] = (x[i] **2)\n",
    "    t= 0\n",
    "    for i in range(0,len(x)):\n",
    "        for j in range(i+1,len(x)):\n",
    "            z [t] = x[i] * x [j] \n",
    "            t+=1\n",
    "    x = np.append(x,y)\n",
    "    x = np.append(x,z)\n",
    "    x = np.atleast_2d(x)\n",
    "    return x   \n",
    "\n",
    "\n",
    "''' Create Basis Functions '''\n",
    "def create_basis_function_train(data):\n",
    "    for j in range(1,11):\n",
    "        data ['X'+str(j)+'**2'] = data['X'+str(j)]**2\n",
    "    for k in range(1,11):\n",
    "        for l in range(k+1,11):\n",
    "            data ['X'+str(k)+'X'+str(l)] = data['X'+str(k)] * data ['X'+str(l)]\n",
    "    f_original = data['Y = F(X1,X2)']\n",
    "    robust_original = data['Y = robust_regularization(X1,X2)']\n",
    "    composite_original = data ['Y = composite(X1,X2)']\n",
    "    del data['Y = F(X1,X2)']\n",
    "    del data['Y = robust_regularization(X1,X2)']\n",
    "    del data ['Y = composite(X1,X2)']\n",
    "    data['Y = F(X1,X2)'] = f_original\n",
    "    data['Y = robust_regularization(X1,X2)'] = robust_original\n",
    "    data ['Y = composite(X1,X2)'] = composite_original\n",
    "    return data\n",
    "\n",
    "def create_basis_function_test(data):\n",
    "    for j in range(1,11):\n",
    "        data ['X'+str(j)+'**2'] = data['X'+str(j)]**2\n",
    "    for k in range(1,11):\n",
    "        for l in range(k+1,11):\n",
    "            data ['X'+str(k)+'X'+str(l)] = data['X'+str(k)] * data ['X'+str(l)]\n",
    "    true_minimax = np.array(data.True_Minimax)\n",
    "    true_composite = np.array(data.True_Composite)\n",
    "    del data['True_Minimax']\n",
    "    del data ['True_Composite']\n",
    "    data['True_Minimax'] = pd.Series(true_minimax)\n",
    "    data ['True_Composite'] = pd.Series(true_composite)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Elastic Net Regression for Minimax Robustness'''\n",
    "def elastic_net_minimax(train_data,test_data):\n",
    "    scaler =  MinMaxScaler().fit(np.r_[train_data.iloc[:,:65].values, test_data.values])\n",
    "    regr=ElasticNet(alpha= 0.009782831659031866 ,random_state=0 , l1_ratio= 0.22322322322322322 , fit_intercept =True, max_iter=1000,selection='random'\n",
    "                   ).fit(scaler.transform(train_data.iloc[:,:65]), train_data.iloc[:,66])\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = create_function_basis(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler, regr)\n",
    "\n",
    "''' Elastic Net Regression for Minimax Robustness'''\n",
    "def elastic_net_composite(train_data,test_data):\n",
    "    scaler =  MinMaxScaler().fit(np.r_[train_data.iloc[:,:65].values, test_data.values])\n",
    "    regr=ElasticNet(alpha= 0.006493421766031815     ,random_state=0 , l1_ratio= 1.0, fit_intercept =True, max_iter=1000,selection='random'\n",
    "                   ).fit(scaler.transform(train_data.iloc[:,:65]), train_data.iloc[:,-1])\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = create_function_basis(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler, regr)\n",
    "\n",
    "\n",
    "''' Kriging for Robust Regularization'''\n",
    "def kriging_minimax(train_data,test_data):\n",
    "    kernel =  RBF( 74, (99, 83935) )\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:10].values, test_data.values])\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel,n_restarts_optimizer=93,random_state=0,\n",
    "                                   normalize_y=True ).fit(scaler.transform(train_data.iloc[:,:10]), train_data.iloc[:,11])\n",
    "    pred = gpr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, gpr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return gpr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return gpr,pred, predict(scaler,gpr)\n",
    "\n",
    "\n",
    "''' Kriging for Robust Composition'''\n",
    "def kriging_composite(train_data,test_data):\n",
    "    kernel =  RBF( 10, (75, 28334) )\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:10].values, test_data.values])\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel,n_restarts_optimizer=45,random_state=0,\n",
    "                                   normalize_y=True ).fit(scaler.transform(train_data.iloc[:,:10]), train_data.iloc[:,-1])\n",
    "    pred = gpr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, gpr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return gpr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return gpr,pred, predict(scaler,gpr)\n",
    "\n",
    "\n",
    "''' Random Forest Implementation for Minimax Robustness'''\n",
    "def rf_minimax(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:10].values, test_data.values])\n",
    "    regr = RandomForestRegressor(random_state=13,n_estimators=91\n",
    "                                ).fit(scaler.transform(train_data.iloc[:,:10]), train_data.iloc[:,11])\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler,regr)\n",
    "\n",
    "''' Random Forest Implementation for Composite Robustness'''\n",
    "def rf_composite(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:10].values, test_data.values])\n",
    "    regr = RandomForestRegressor(random_state=37,n_estimators=77\n",
    "                                ).fit(scaler.transform(train_data.iloc[:,:10]), train_data.iloc[:,-1])\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler,regr)\n",
    "\n",
    "\n",
    "''' KNN Regression Implementation for Minimax Robustness'''\n",
    "def KNN_minimax(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:10].values, test_data.values])\n",
    "    regr = KNeighborsRegressor(n_neighbors=8,weights='distance',algorithm='brute',p=2\n",
    "                               ).fit(scaler.transform(train_data.iloc[:,:10]), train_data.iloc[:,11])\n",
    "\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler,regr)\n",
    "\n",
    "''' KNN Regression Implementation for Composite Robustness'''\n",
    "def KNN_composite(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:10].values, test_data.values])\n",
    "    regr = KNeighborsRegressor(n_neighbors=4,weights='distance',algorithm='brute',p=2\n",
    "                               ).fit(scaler.transform(train_data.iloc[:,:10]), train_data.iloc[:,-1])\n",
    "\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler,regr)\n",
    "\n",
    "''' Support Vector Regression for Robust Regularization'''\n",
    "def SVR_minimax(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:10].values, test_data.values])\n",
    "    gpr = SVR(gamma =  8.53443233e-02    ,C =  7.03315585e+02 , epsilon=0.2,max_iter=1500).fit(\n",
    "        scaler.transform(train_data.iloc[:,:10]), train_data.iloc[:,11])\n",
    "    pred = gpr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, gpr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return gpr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return gpr,pred, predict(scaler,gpr)\n",
    "\n",
    "''' Support Vector Regression for Robust Composition'''\n",
    "def SVR_composite(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:10].values, test_data.values])\n",
    "    gpr = SVR(gamma = 8.53443233e-02 ,C =  7.03315585e+02 , epsilon=0.2,max_iter=1500).fit(\n",
    "        scaler.transform(train_data.iloc[:,:10]), train_data.iloc[:,-1])\n",
    "    pred = gpr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, gpr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return gpr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return gpr,pred, predict(scaler,gpr)\n",
    "\n",
    "\n",
    "''' RBF Network Interpolation for Robust Regularization'''\n",
    "def RBF_minimax(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:10].values, test_data.values])\n",
    "    model = RBFN(hidden_shape=90, sigma= 0.001)\n",
    "    model.fit(scaler.transform(np.array(train_data.iloc[:,:10])), np.array(train_data.iloc[:,11]))\n",
    "    pred = model.predict(scaler.transform(np.array(test_data)))\n",
    "    def predict(scaler, model):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return model.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return model,pred, predict(scaler,model)\n",
    "\n",
    "''' RBF Network Interpolation for Robust Composition'''\n",
    "def RBF_composite(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:10].values, test_data.values])\n",
    "    model = RBFN(hidden_shape=90, sigma= 0.001000)\n",
    "    model.fit(scaler.transform(np.array(train_data.iloc[:,:10])), np.array(train_data.iloc[:,-1]))\n",
    "    pred = model.predict(scaler.transform(np.array(test_data)))\n",
    "    def predict(scaler, model):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return model.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return model,pred, predict(scaler,model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(sys.path[1]+str('\\\\Training_Data_Sets\\\\500Samples.csv')).iloc[:,1:]\n",
    "test = pd.read_csv(sys.path[1]+str('\\\\Test_Data_Sets\\\\750Samples.csv')).iloc[:,1:]\n",
    "model_k_m,pred_k_m, predict_k_m = kriging_minimax(train,test.iloc[:,:10])\n",
    "model_k_c,pred_k_c, predict_k_c = kriging_composite(train,test.iloc[:,:10])\n",
    "model_r_m,pred_r_m, predict_r_m = rf_minimax(train,test.iloc[:,:10])\n",
    "model_r_c,pred_r_c, predict_r_c = rf_composite(train,test.iloc[:,:10])\n",
    "model_n_m,pred_n_m, predict_n_m = KNN_minimax(train,test.iloc[:,:10])\n",
    "model_n_c,pred_n_c , predict_n_c= KNN_composite(train,test.iloc[:,:10])\n",
    "model_s_m,pred_s_m, predict_s_m = SVR_minimax(train,test.iloc[:,:10])\n",
    "model_s_c,pred_s_c, predict_s_c = SVR_composite(train,test.iloc[:,:10])\n",
    "model_b_m,pred_b_m, predict_b_m = RBF_minimax(train,test.iloc[:,:10])\n",
    "model_b_c,pred_b_c, predict_b_c = RBF_composite(train,test.iloc[:,:10])\n",
    "train = create_basis_function_train(train)\n",
    "test = create_basis_function_test(test)\n",
    "model_m_m,pred_m_m, predict_m_m = elastic_net_minimax(train,test.iloc[:,:65])\n",
    "model_m_c,pred_m_c, predict_m_c = elastic_net_composite(train,test.iloc[:,:65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = ['Benchmark', 'Kriging' , 'SVM' , 'RBFN' ,  'KNN' , 'RF'  , 'ELN' ]\n",
    "Cols = []\n",
    "for j in range(len(Columns)):\n",
    "    for i in range(1,11):\n",
    "        Cols.append(Columns[j]+'_X'+str(i))\n",
    "        \n",
    "const = Bounds([-5.12,-5.12,-5.12,-5.12,-5.12,-5.12,-5.12,-5.12,-5.12,-5.12], \n",
    "               [5.12,5.12,5.12,5.12,5.12,5.12,5.12,5.12,5.12,5.12])\n",
    "\n",
    "G1,G2,G3,G4,G5,G6,G7,G8,G9,G10 = DOE(100)\n",
    "G1 = linearscaletransform(G1,range_out=(-5.12,5.12))\n",
    "G2 = linearscaletransform(G2,range_out=(-5.12,5.12))\n",
    "G3 = linearscaletransform(G3,range_out=(-5.12,5.12))\n",
    "G4 = linearscaletransform(G4,range_out=(-5.12,5.12))\n",
    "G5 = linearscaletransform(G5,range_out=(-5.12,5.12))\n",
    "G6 = linearscaletransform(G6,range_out=(-5.12,5.12))\n",
    "G7 = linearscaletransform(G7,range_out=(-5.12,5.12))\n",
    "G8 = linearscaletransform(G8,range_out=(-5.12,5.12))\n",
    "G9 = linearscaletransform(G9,range_out=(-5.12,5.12))\n",
    "G10 = linearscaletransform(G10,range_out=(-5.12,5.12))\n",
    "\n",
    "\n",
    "\n",
    "X_Values_RR = np.zeros([100,70])\n",
    "X_Values_RC = np.zeros([100,70])\n",
    "Fun_Eval_RR = np.zeros([100,7])\n",
    "Fun_Eval_RC = np.zeros([100,7])\n",
    "opt = {'maxiter':50}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLSQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_Values_RR.shape[0]):\n",
    "    min_robust = minimize(robust_regularization,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i],G6[i],G7[i],G8[i],G9[i],G10[i]])),method='SLSQP',bounds=const,options=opt)\n",
    "    min_compo = minimize(composite_robustness,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i],G6[i],G7[i],G8[i],G9[i],G10[i]])),method='SLSQP',bounds=const,options=opt)\n",
    "    min_robust_k = minimize(predict_k_m,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i],G6[i],G7[i],G8[i],G9[i],G10[i]])),method='SLSQP',bounds=const,options=opt)\n",
    "    min_composite_k = minimize(predict_k_c,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i],G6[i],G7[i],G8[i],G9[i],G10[i]])),method='SLSQP',bounds=const,options=opt)\n",
    "    min_robust_s = minimize(predict_s_m,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i],G6[i],G7[i],G8[i],G9[i],G10[i]])),method='SLSQP',bounds=const,options=opt)\n",
    "    min_composite_s = minimize(predict_s_c,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i],G6[i],G7[i],G8[i],G9[i],G10[i]])),method='SLSQP',bounds=const,options=opt)\n",
    "    min_robust_b = minimize(predict_b_m,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i],G6[i],G7[i],G8[i],G9[i],G10[i]])),method='SLSQP',bounds=const,options=opt)\n",
    "    min_composite_b = minimize(predict_b_c,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i],G6[i],G7[i],G8[i],G9[i],G10[i]])),method='SLSQP',bounds=const,options=opt)\n",
    "    min_robust_n = minimize(predict_n_m,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i],G6[i],G7[i],G8[i],G9[i],G10[i]])),method='SLSQP',bounds=const,options=opt)\n",
    "    min_composite_n = minimize(predict_n_c,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i],G6[i],G7[i],G8[i],G9[i],G10[i]])),method='SLSQP',bounds=const,options=opt)\n",
    "    min_robust_r = minimize(predict_r_m,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i],G6[i],G7[i],G8[i],G9[i],G10[i]])),method='SLSQP',bounds=const,options=opt)\n",
    "    min_composite_r = minimize(predict_r_c,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i],G6[i],G7[i],G8[i],G9[i],G10[i]])),method='SLSQP',bounds=const,options=opt)\n",
    "    min_robust_m = minimize(predict_m_m,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i],G6[i],G7[i],G8[i],G9[i],G10[i]])),method='SLSQP',bounds=const,options=opt)\n",
    "    min_composite_m = minimize(predict_m_c,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i],G6[i],G7[i],G8[i],G9[i],G10[i]])),method='SLSQP',bounds=const,options=opt)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    X_Values_RR [i,:] = list(min_robust.x)+list(min_robust_k.x)+list(min_robust_s.x)+list(min_robust_b.x)+list(min_robust_n.x)+list(min_robust_r.x)+list(min_robust_m.x)\n",
    "    \n",
    "    X_Values_RC [i,:] = list(min_compo.x)+list(min_composite_k.x)+list(min_composite_s.x)+list(min_composite_b.x)+list(min_composite_n.x)+list(min_composite_r.x)+list(min_composite_m.x)\n",
    "    \n",
    "    Fun_Eval_RR [i,:] = [min_robust.nfev]+[100,100,100,100,100,100]\n",
    "    \n",
    "    Fun_Eval_RC [i,:] = [min_compo.nfev]+[100,100,100,100,100,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Values_RR = pd.DataFrame(X_Values_RR)\n",
    "X_Values_RR.columns = Cols\n",
    "X_Values_RC = pd.DataFrame(X_Values_RC)\n",
    "X_Values_RC.columns = Cols\n",
    "Fun_Eval_RR = pd.DataFrame(Fun_Eval_RR)\n",
    "Fun_Eval_RR.columns = Columns\n",
    "Fun_Eval_RC = pd.DataFrame(Fun_Eval_RC)\n",
    "Fun_Eval_RC.columns = Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Values_RR = pd.DataFrame(X_Values_RR)\n",
    "X_Values_RR.columns = Cols\n",
    "X_Values_RC = pd.DataFrame(X_Values_RC)\n",
    "X_Values_RC.columns = Cols\n",
    "Fun_Eval_RR = pd.DataFrame(Fun_Eval_RR)\n",
    "Fun_Eval_RR.columns = Columns\n",
    "Fun_Eval_RC = pd.DataFrame(Fun_Eval_RC)\n",
    "Fun_Eval_RC.columns = Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Values_RR.to_csv('Results\\\\X_Values_RR.csv')\n",
    "X_Values_RC.to_csv('Results\\\\X_Values_RC.csv')\n",
    "Fun_Eval_RR.to_csv('Results\\\\Function_Eval_RR.csv')\n",
    "Fun_Eval_RC.to_csv('Results\\\\Function_Eval_RC.csv')\n",
    "RR = pd.read_csv('Results\\\\X_Values_RR.csv').iloc[:,1:]\n",
    "RC = pd.read_csv('Results\\\\X_Values_RC.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bench_Fun_RR = np.zeros(100)\n",
    "Krig_Fun_RR = np.zeros(100)\n",
    "SVM_Fun_RR = np.zeros(100)\n",
    "RBFN_Fun_RR = np.zeros(100)\n",
    "KNN_Fun_RR = np.zeros(100)\n",
    "RF_Fun_RR = np.zeros(100)\n",
    "ELN_Fun_RR = np.zeros(100)\n",
    "for i in range(X_Values_RR.shape[0]):\n",
    "    Bench_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,:10])\n",
    "    Krig_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,10:20])\n",
    "    SVM_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,20:30])\n",
    "    RBFN_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,30:40])\n",
    "    KNN_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,40:50])\n",
    "    RF_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,50:60])\n",
    "    ELN_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,60:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLSQP\n",
      "ModeResult(mode=array([918.90418693]), count=array([1])) 40.0400574218273\n",
      "Kriging\n",
      "ModeResult(mode=array([1038.30460493]), count=array([1])) 53.761180727327115\n",
      "SVM\n",
      "ModeResult(mode=array([952.48414242]), count=array([1])) 0.02373913100416325\n",
      "RBFN\n",
      "ModeResult(mode=array([1033.37983989]), count=array([1])) 49.88780093211833\n",
      "KNN\n",
      "ModeResult(mode=array([974.75554433]), count=array([1])) 30.770567825819672\n",
      "RF\n",
      "ModeResult(mode=array([1046.84898377]), count=array([1])) 52.62300540136485\n",
      "ELN\n",
      "ModeResult(mode=array([1032.21296732]), count=array([1])) 0.021996387059738356\n"
     ]
    }
   ],
   "source": [
    "print ('SLSQP')\n",
    "print (stats.mode(Bench_Fun_RR) , np.std(Bench_Fun_RR))\n",
    "print ('Kriging')\n",
    "print (stats.mode(Krig_Fun_RR) , np.std(Krig_Fun_RR))\n",
    "print ('SVM')\n",
    "print (stats.mode(SVM_Fun_RR) , np.std(SVM_Fun_RR))\n",
    "print ('RBFN')\n",
    "print (stats.mode(RBFN_Fun_RR) , np.std(RBFN_Fun_RR))\n",
    "print ('KNN')\n",
    "print (stats.mode(KNN_Fun_RR) , np.std(KNN_Fun_RR))\n",
    "print ('RF')\n",
    "print (stats.mode(RF_Fun_RR) , np.std(RF_Fun_RR))\n",
    "print ('ELN')\n",
    "print (stats.mode(ELN_Fun_RR) , np.std(ELN_Fun_RR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bench_Fun_RC = np.zeros(100)\n",
    "Krig_Fun_RC = np.zeros(100)\n",
    "SVM_Fun_RC = np.zeros(100)\n",
    "RBFN_Fun_RC = np.zeros(100)\n",
    "KNN_Fun_RC = np.zeros(100)\n",
    "RF_Fun_RC = np.zeros(100)\n",
    "ELN_Fun_RC = np.zeros(100)\n",
    "for i in range(X_Values_RC.shape[0]):\n",
    "    Bench_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,:10])\n",
    "    Krig_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,10:20])\n",
    "    SVM_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,20:30])\n",
    "    RBFN_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,30:40])\n",
    "    KNN_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,40:50])\n",
    "    RF_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,50:60])\n",
    "    ELN_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,60:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLSQP\n",
      "ModeResult(mode=array([1003.4000837]), count=array([1])) 12.134756680628389\n",
      "Kriging\n",
      "ModeResult(mode=array([1057.55901114]), count=array([1])) 23.840130856618025\n",
      "SVM\n",
      "ModeResult(mode=array([1044.6362973]), count=array([1])) 0.017307890156653735\n",
      "RBFN\n",
      "ModeResult(mode=array([1040.77422711]), count=array([1])) 23.478400330661987\n",
      "KNN\n",
      "ModeResult(mode=array([1023.47266488]), count=array([1])) 25.391563414351623\n",
      "RF\n",
      "ModeResult(mode=array([1063.85092953]), count=array([1])) 25.25585447377904\n",
      "ELN\n",
      "ModeResult(mode=array([1054.53706032]), count=array([1])) 0.003001863736954622\n"
     ]
    }
   ],
   "source": [
    "print ('SLSQP')\n",
    "print (stats.mode(Bench_Fun_RC) , np.std(Bench_Fun_RC))\n",
    "print ('Kriging')\n",
    "print (stats.mode(Krig_Fun_RC) , np.std(Krig_Fun_RC))\n",
    "print ('SVM')\n",
    "print (stats.mode(SVM_Fun_RC) , np.std(SVM_Fun_RC))\n",
    "print ('RBFN')\n",
    "print (stats.mode(RBFN_Fun_RC) , np.std(RBFN_Fun_RC))\n",
    "print ('KNN')\n",
    "print (stats.mode(KNN_Fun_RC) , np.std(KNN_Fun_RC))\n",
    "print ('RF')\n",
    "print (stats.mode(RF_Fun_RC) , np.std(RF_Fun_RC))\n",
    "print ('ELN')\n",
    "print (stats.mode(ELN_Fun_RC) , np.std(ELN_Fun_RC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11,46 thursday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
