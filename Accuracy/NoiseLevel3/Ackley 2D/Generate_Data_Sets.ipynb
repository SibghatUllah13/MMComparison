{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pyDOE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Utils \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import namedtuple\n",
    "from matplotlib import cm\n",
    "import cma\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValueRange = namedtuple('ValueRange', ['min', 'max'])\n",
    "\n",
    "def determinerange(values):\n",
    "    \"\"\"Determine the range of values in each dimension\"\"\"\n",
    "    return ValueRange(np.min(values, axis=0), np.max(values, axis=0))\n",
    "\n",
    "\n",
    "def linearscaletransform(values, *, range_in=None, range_out=ValueRange(0, 1), scale_only=False):\n",
    "    \"\"\"Perform a scale transformation of `values`: [range_in] --> [range_out]\"\"\"\n",
    "\n",
    "    if range_in is None:\n",
    "        range_in = determinerange(values)\n",
    "    elif not isinstance(range_in, ValueRange):\n",
    "        range_in = ValueRange(*range_in)\n",
    "\n",
    "    if not isinstance(range_out, ValueRange):\n",
    "        range_out = ValueRange(*range_out)\n",
    "\n",
    "    scale_out = range_out.max - range_out.min\n",
    "    scale_in = range_in.max - range_in.min\n",
    "\n",
    "    if scale_only:\n",
    "        scaled_values = (values / scale_in) * scale_out\n",
    "    else:\n",
    "        scaled_values = (values - range_in.min) / scale_in\n",
    "        scaled_values = (scaled_values * scale_out) + range_out.min\n",
    "\n",
    "    return scaled_values\n",
    "\n",
    "\n",
    "''' Plot the Graph of the Function'''\n",
    "def plot_the_graph(x,y,z,graph_title):\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    ax = Axes3D(fig)\n",
    "    surf = ax.plot_trisurf(x,y,z,cmap=cm.jet, linewidth=0.3,alpha=0.9)\n",
    "    fig.colorbar(surf, shrink=10, aspect=3)\n",
    "    ax.set_xlabel('X1')\n",
    "    ax.set_ylabel('X2')\n",
    "    ax.set_zlabel('Robust(X1,X2)')\n",
    "    plt.title(graph_title)\n",
    "    plt.show()\n",
    "    fig.savefig(graph_title+'.pdf')\n",
    "\n",
    "''' Original Function for Optimization '''\n",
    "def ackley_2D(X):\n",
    "    x1,x2 = X\n",
    "    A = (-20 *  np.exp (-0.2 * np.sqrt(( (x1**2) + (x2**2) ) / (2) ) ) )\n",
    "    B = np.exp (((np.cos(2 * np.pi * x1 ) ) + (np.cos(2 * np.pi * x2 ) ) ) / (2) )\n",
    "    return A - B +20 +np.exp(1)\n",
    "\n",
    "''' Latin HyperCube Sampling Design of Experiment '''\n",
    "def DOE(n_obs):\n",
    "    np.random.seed(0)\n",
    "    lhd = pyDOE.lhs(n=2, samples=n_obs, criterion='m')\n",
    "    X1, X2 = lhd[:,0], lhd[:,1]\n",
    "    return X1,X2\n",
    "\n",
    "\n",
    "'''Robust Regularization based on minimax Principle 5% perturbations'''\n",
    "def robust_regularization(X):\n",
    "    x1,x2 = X\n",
    "    eps = np.linspace(-13.1072,13.1072,2000)\n",
    "    return np.max( ackley_2D([x1+eps,x2+eps]) )\n",
    "\n",
    "''' Robustness based on a composite function of Mean and STd '''\n",
    "def composite_robustness(X):\n",
    "    w=1\n",
    "    x1,x2 = X\n",
    "    np.random.seed(0)\n",
    "    eps = np.random.normal(loc=0.0,scale= 2.1845333333333334 ,size=10000)\n",
    "    sample_points = ackley_2D([x1+eps,x2+eps])\n",
    "    sample_mean = np.mean(sample_points)\n",
    "    variance = np.square(sample_points-sample_mean)\n",
    "    std = np.sqrt(np.mean(variance))\n",
    "    std = np.sqrt(np.mean(variance))\n",
    "    return sample_mean + w * std\n",
    "\n",
    "''' Generate Training Data using LHD along side the Output of the Robust System'''\n",
    "def generate_training_data(n_obs):\n",
    "    X1,X2 = DOE(n_obs)\n",
    "    X1 = linearscaletransform(X1,range_out=(-32.768,32.768))\n",
    "    X2 = linearscaletransform(X2,range_out=(-32.768,32.768))\n",
    "    f_evaluation = ackley_2D([X1,X2])\n",
    "    f_original = np.zeros(X1.shape[0])\n",
    "    minimax_original = np.zeros(X1.shape[0])\n",
    "    composite_original = np.zeros(X1.shape[0])\n",
    "    for i in range(X1.shape[0]):\n",
    "        f_original[i] = ackley_2D([X1[i],X2[i]])\n",
    "        minimax_original[i] = robust_regularization([X1[i],X2[i]])\n",
    "        composite_original[i] = composite_robustness([X1[i],X2[i]])\n",
    "    train = pd.DataFrame()\n",
    "    train['X1'] = pd.Series(X1)\n",
    "    train['X2'] = pd.Series(X2)\n",
    "    train['Y = F(X1,X2)'] = pd.Series(f_original)\n",
    "    train['Y = robust_regularization(X1,X2)'] = pd.Series(minimax_original)\n",
    "    train['Y = composite(X1,X2)'] = pd.Series(composite_original)\n",
    "    train.to_csv('Training_Data_Sets\\\\'+str(n_obs)+'Samples.csv')\n",
    "    return train\n",
    "\n",
    "''' Generate Test Data using LHD along side the Output of the Robust System'''\n",
    "def generate_test_data(n_obs):\n",
    "    test = pd.DataFrame()\n",
    "    np.random.seed(0)\n",
    "    lhd = pyDOE.lhs(n=2, samples=n_obs, criterion='m')\n",
    "    X1 = linearscaletransform(lhd[:,0],range_out=(-32.768,32.768))\n",
    "    X2 = linearscaletransform(lhd[:,1],range_out=(-32.768,32.768))\n",
    "    test ['X1'] = pd.Series(X1)\n",
    "    test ['X2'] = pd.Series(X2)\n",
    "    true_minimax = np.zeros(test.shape[0])\n",
    "    true_composite = np.zeros(test.shape[0])\n",
    "    for i in range(test.shape[0]):\n",
    "        true_minimax[i] = robust_regularization(test.iloc[i,:])\n",
    "        true_composite[i] = composite_robustness(test.iloc[i,:])\n",
    "    test ['True_Minimax'] = pd.Series(true_minimax)\n",
    "    test ['True_Composite'] = pd.Series(true_composite)\n",
    "    test.to_csv('Test_Data_Sets\\\\'+str(n_obs)+'Samples.csv')\n",
    "    return test\n",
    "\n",
    "''' Check if There are same examples in Test and Train Data Sets'''\n",
    "def check_data_sets(train,test):\n",
    "    C = train.isin(test)\n",
    "    C = pd.DataFrame.sum(C,axis=1)\n",
    "    ids = C.index[C>1]\n",
    "    print ('Total Number of Input Observations present in Test Data : '+str(ids.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMA-ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3_w,6)-aCMA-ES (mu_w=2.0,w_1=63%) in dimension 2 (seed=36067, Sun Mar 31 11:33:16 2019)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1      6 2.067128919446219e+01 1.0e+00 1.22e+01  1e+01  1e+01 0:00.0\n",
      "    2     12 2.134310908778974e+01 1.1e+00 1.05e+01  8e+00  9e+00 0:00.0\n",
      "    3     18 2.109097454580077e+01 1.1e+00 7.71e+00  5e+00  6e+00 0:00.0\n",
      "  100    600 2.044507397942090e+01 5.3e+02 4.54e-03  6e-05  6e-05 0:00.4\n",
      "  200   1200 2.019204155903400e+01 1.9e+01 4.94e-01  4e-06  5e-06 0:00.7\n",
      "  262   1572 2.019203999327260e+01 1.1e+01 2.29e-04  8e-12  9e-12 0:00.9\n",
      "termination on tolx=1e-11 (Sun Mar 31 11:33:18 2019)\n",
      "final/bestever f-value = 2.019204e+01 2.019204e+01\n",
      "incumbent solution: [-0.7654614758449952, 0.7654614758516475]\n",
      "std deviation: [8.20042325163196e-12, 8.660134894390303e-12]\n",
      "(3_w,6)-aCMA-ES (mu_w=2.0,w_1=63%) in dimension 2 (seed=192217, Sun Mar 31 11:33:18 2019)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1      6 1.608618064297234e+01 1.0e+00 1.36e+01  1e+01  1e+01 0:00.0\n",
      "    2     12 1.185481692287950e+01 1.2e+00 1.17e+01  8e+00  1e+01 0:00.0\n",
      "    3     18 1.716024565608213e+01 1.3e+00 1.11e+01  8e+00  9e+00 0:00.0\n",
      "  100    600 1.109346622575057e+01 9.8e+01 3.62e-06  6e-09  3e-08 0:00.9\n",
      "  129    774 1.109346622590773e+01 4.2e+02 1.72e-08  6e-12  3e-11 0:01.2\n",
      "termination on tolfun=1e-11 (Sun Mar 31 11:33:21 2019)\n",
      "final/bestever f-value = 1.109347e+01 1.083801e+01\n",
      "incumbent solution: [-0.4627064246407989, -1.5303216269651019]\n",
      "std deviation: [2.5938970281332475e-11, 6.243213340744731e-12]\n"
     ]
    }
   ],
   "source": [
    "opt = {'seed': 0 , 'maxfevals': 1e6  }\n",
    "rr = cma.fmin(robust_regularization, 2 * [0] , 16.4 , options=opt  )\n",
    "rc = cma.fmin(composite_robustness, 2 * [0] , 16.4 , options=opt  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xmin for RR :[-0.76546148  0.76546148]\n",
      "Fmin for RR :20.19203999327172\n",
      "Xmin for RC :[ 0.70841014 -1.32359855]\n",
      "Fmin for RC :10.838010260179216\n"
     ]
    }
   ],
   "source": [
    "print ('Xmin for RR :'+str(rr[0]))\n",
    "print ('Fmin for RR :'+str(rr[1]))\n",
    "print ('Xmin for RC :'+str(rc[0]))\n",
    "print ('Fmin for RC :'+str(rc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLSQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "const = Bounds([-32.768, -32.768], [32.768, 32.768])\n",
    "min_robust = minimize(robust_regularization,(0,0),method='SLSQP',bounds=const)\n",
    "min_compo = minimize(composite_robustness,(0,0),method='SLSQP',bounds=const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 20.712178505923514\n",
       "     jac: array([0.03909802, 0.03909802])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 15\n",
       "     nit: 1\n",
       "    njev: 1\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([-2.54400789e-07, -2.54400789e-07])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 10.332947706302381\n",
       "     jac: array([0.00020993, 0.00020993])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 12\n",
       "     nit: 3\n",
       "    njev: 3\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([0.04302142, 0.04302142])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_compo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "lhd = pyDOE.lhs(n=2, samples= 1000, criterion='m')\n",
    "X1 = linearscaletransform(lhd[:,0],range_out=(-32.768,32.768))\n",
    "X2 = linearscaletransform(lhd[:,1],range_out=(-32.768,32.768))\n",
    "Data = pd.DataFrame()\n",
    "Data['X1'] = pd.Series(X1)\n",
    "Data['X2'] = pd.Series(X2)\n",
    "Data.to_csv('Optimization_Test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(sys.path[1]+str('\\\\Training_Data_Sets\\\\100Samples.csv')).iloc[:,1:]\n",
    "test = pd.read_csv('Optimization_Test.csv').iloc[:,1:]\n",
    "model_k_m,pred_k_m = Utils.kriging_minimax(train,test.iloc[:,:2])\n",
    "model_k_c,pred_k_c = Utils.kriging_composite(train,test.iloc[:,:2])\n",
    "model_r_m,pred_r_m = Utils.rf_minimax(train,test.iloc[:,:2])\n",
    "model_r_c,pred_r_c = Utils.rf_composite(train,test.iloc[:,:2])\n",
    "model_n_m,pred_n_m = Utils.KNN_minimax(train,test.iloc[:,:2])\n",
    "model_n_c,pred_n_c = Utils.KNN_composite(train,test.iloc[:,:2])\n",
    "model_s_m,pred_s_m = Utils.SVR_minimax(train,test.iloc[:,:2])\n",
    "model_s_c,pred_s_c = Utils.SVR_composite(train,test.iloc[:,:2])\n",
    "model_b_m,pred_b_m = Utils.RBF_minimax(train,test.iloc[:,:2])\n",
    "model_b_c,pred_b_c = Utils.RBF_composite(train,test.iloc[:,:2])\n",
    "train ['X1X2'] = pd.Series( np.array(train.X1) * np.array(train.X2) )\n",
    "train ['X1**2'] = pd.Series ( np.array(train.X1)**2 )\n",
    "train ['X2**2'] = pd.Series ( np.array(train.X2)**2 )\n",
    "f_original = train['Y = F(X1,X2)']\n",
    "robust_original = train['Y = robust_regularization(X1,X2)']\n",
    "composite_original = train ['Y = composite(X1,X2)']\n",
    "del train['Y = F(X1,X2)']\n",
    "del train['Y = robust_regularization(X1,X2)']\n",
    "del train ['Y = composite(X1,X2)']\n",
    "train['Y = F(X1,X2)'] = f_original\n",
    "train['Y = robust_regularization(X1,X2)'] = robust_original\n",
    "train ['Y = composite(X1,X2)'] = composite_original\n",
    "test ['X1X2'] =  pd.Series( np.array(test.X1) * np.array(test.X2) )\n",
    "test ['X1**2'] = pd.Series ( np.array(test.X1)**2 )\n",
    "test ['X2**2'] = pd.Series ( np.array(test.X2)**2 )\n",
    "model_m_m,pred_m_m = Utils.elastic_net_minimax(train,test.iloc[:,:5])\n",
    "model_m_c,pred_m_c = Utils.elastic_net_composite(train,test.iloc[:,:5])\n",
    "del train['X1X2']\n",
    "del train['X1**2']\n",
    "del train['X2**2']\n",
    "del test['X1X2']\n",
    "del test['X1**2']\n",
    "del test['X2**2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using Kriging is : 20.995243819151302\n",
      "At X = :[-0.80030553 -0.71519228]\n",
      "RC :  Minimum Using Kriging is : 10.75776662328985\n",
      "At X = :[-1.20453403 -0.04415047]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using Kriging is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_k_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_k_m),:])))\n",
    "print ('RC :  Minimum Using Kriging is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_k_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_k_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using SVR  is : 20.758115455448856\n",
      "At X = :[-2.10204467  1.95926136]\n",
      "RC :  Minimum Using SVR is : 10.75196254400584\n",
      "At X = :[-0.80030553 -0.71519228]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using SVR  is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_s_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_s_m),:])))\n",
    "print ('RC :  Minimum Using SVR is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_s_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_s_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using KNN is : 20.62054420863261\n",
      "At X = :[-3.25609051  1.26503354]\n",
      "RC :  Minimum Using KNN is : 11.493516470668506\n",
      "At X = :[1.95129025 0.67959169]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using KNN is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_n_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_n_m),:])))\n",
    "print ('RC :  Minimum Using KNN is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_n_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_n_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using RF is : 20.821907113434886\n",
      "At X = :[2.72416023 2.19294009]\n",
      "RC :  Minimum Using RF is : 12.330436419042755\n",
      "At X = :[2.54164273 1.10773633]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using RF is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_r_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_r_m),:])))\n",
    "print ('RC :  Minimum Using RF is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_r_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_r_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using RBFN is : 20.684162160993214\n",
      "At X = :[-3.36653792  0.12298411]\n",
      "RC :  Minimum Using RBFN is : 10.75196254400584\n",
      "At X = :[-0.80030553 -0.71519228]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using RBFN is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_b_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_b_m),:])))\n",
    "print ('RC :  Minimum Using RBFN is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_b_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_b_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using ELN is : 20.995243819151302\n",
      "At X = :[-0.80030553 -0.71519228]\n",
      "RC :  Minimum Using ELN is : 10.75196254400584\n",
      "At X = :[-0.80030553 -0.71519228]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using ELN is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_m_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_m_m),:])))\n",
    "print ('RC :  Minimum Using ELN is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_m_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_m_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
