{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyDOE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Utils \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import namedtuple\n",
    "from matplotlib import cm\n",
    "import cma\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValueRange = namedtuple('ValueRange', ['min', 'max'])\n",
    "\n",
    "def determinerange(values):\n",
    "    \"\"\"Determine the range of values in each dimension\"\"\"\n",
    "    return ValueRange(np.min(values, axis=0), np.max(values, axis=0))\n",
    "\n",
    "\n",
    "def linearscaletransform(values, *, range_in=None, range_out=ValueRange(0, 1), scale_only=False):\n",
    "    \"\"\"Perform a scale transformation of `values`: [range_in] --> [range_out]\"\"\"\n",
    "\n",
    "    if range_in is None:\n",
    "        range_in = determinerange(values)\n",
    "    elif not isinstance(range_in, ValueRange):\n",
    "        range_in = ValueRange(*range_in)\n",
    "\n",
    "    if not isinstance(range_out, ValueRange):\n",
    "        range_out = ValueRange(*range_out)\n",
    "\n",
    "    scale_out = range_out.max - range_out.min\n",
    "    scale_in = range_in.max - range_in.min\n",
    "\n",
    "    if scale_only:\n",
    "        scaled_values = (values / scale_in) * scale_out\n",
    "    else:\n",
    "        scaled_values = (values - range_in.min) / scale_in\n",
    "        scaled_values = (scaled_values * scale_out) + range_out.min\n",
    "\n",
    "    return scaled_values\n",
    "\n",
    "\n",
    "''' Plot the Graph of the Function'''\n",
    "def plot_the_graph(x,y,z,graph_title):\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    ax = Axes3D(fig)\n",
    "    surf = ax.plot_trisurf(x,y,z,cmap=cm.jet, linewidth=0.3,alpha=0.9)\n",
    "    fig.colorbar(surf, shrink=10, aspect=3)\n",
    "    ax.set_xlabel('X1')\n",
    "    ax.set_ylabel('X2')\n",
    "    ax.set_zlabel('Robust(X1,X2)')\n",
    "    plt.title(graph_title)\n",
    "    plt.show()\n",
    "    fig.savefig(graph_title+'.pdf')\n",
    "\n",
    "''' Original Function for Optimization '''\n",
    "def ackley_2D(X):\n",
    "    x1,x2 = X\n",
    "    A = (-20 *  np.exp (-0.2 * np.sqrt(( (x1**2) + (x2**2) ) / (2) ) ) )\n",
    "    B = np.exp (((np.cos(2 * np.pi * x1 ) ) + (np.cos(2 * np.pi * x2 ) ) ) / (2) )\n",
    "    return A - B +20 +np.exp(1)\n",
    "\n",
    "''' Latin HyperCube Sampling Design of Experiment '''\n",
    "def DOE(n_obs):\n",
    "    np.random.seed(0)\n",
    "    lhd = pyDOE.lhs(n=2, samples=n_obs, criterion='m')\n",
    "    X1, X2 = lhd[:,0], lhd[:,1]\n",
    "    return X1,X2\n",
    "\n",
    "\n",
    "'''Robust Regularization based on minimax Principle 5% perturbations'''\n",
    "def robust_regularization(X):\n",
    "    x1,x2 = X\n",
    "    eps = np.linspace(-6.5536,6.5536,2000)\n",
    "    return np.max( ackley_2D([x1+eps,x2+eps]) )\n",
    "\n",
    "''' Robustness based on a composite function of Mean and STd '''\n",
    "def composite_robustness(X):\n",
    "    w=1\n",
    "    x1,x2 = X\n",
    "    np.random.seed(0)\n",
    "    eps = np.random.normal(loc=0.0,scale=1.0922666666666667,size=10000)\n",
    "    sample_points = ackley_2D([x1+eps,x2+eps])\n",
    "    sample_mean = np.mean(sample_points)\n",
    "    variance = np.square(sample_points-sample_mean)\n",
    "    std = np.sqrt(np.mean(variance))\n",
    "    std = np.sqrt(np.mean(variance))\n",
    "    return sample_mean + w * std\n",
    "\n",
    "''' Generate Training Data using LHD along side the Output of the Robust System'''\n",
    "def generate_training_data(n_obs):\n",
    "    X1,X2 = DOE(n_obs)\n",
    "    X1 = linearscaletransform(X1,range_out=(-32.768,32.768))\n",
    "    X2 = linearscaletransform(X2,range_out=(-32.768,32.768))\n",
    "    f_evaluation = ackley_2D([X1,X2])\n",
    "    f_original = np.zeros(X1.shape[0])\n",
    "    minimax_original = np.zeros(X1.shape[0])\n",
    "    composite_original = np.zeros(X1.shape[0])\n",
    "    for i in range(X1.shape[0]):\n",
    "        f_original[i] = ackley_2D([X1[i],X2[i]])\n",
    "        minimax_original[i] = robust_regularization([X1[i],X2[i]])\n",
    "        composite_original[i] = composite_robustness([X1[i],X2[i]])\n",
    "    train = pd.DataFrame()\n",
    "    train['X1'] = pd.Series(X1)\n",
    "    train['X2'] = pd.Series(X2)\n",
    "    train['Y = F(X1,X2)'] = pd.Series(f_original)\n",
    "    train['Y = robust_regularization(X1,X2)'] = pd.Series(minimax_original)\n",
    "    train['Y = composite(X1,X2)'] = pd.Series(composite_original)\n",
    "    train.to_csv('Training_Data_Sets\\\\'+str(n_obs)+'Samples.csv')\n",
    "    return train\n",
    "\n",
    "''' Generate Test Data using LHD along side the Output of the Robust System'''\n",
    "def generate_test_data(n_obs):\n",
    "    test = pd.DataFrame()\n",
    "    np.random.seed(0)\n",
    "    lhd = pyDOE.lhs(n=2, samples=n_obs, criterion='m')\n",
    "    X1 = linearscaletransform(lhd[:,0],range_out=(-32.768,32.768))\n",
    "    X2 = linearscaletransform(lhd[:,1],range_out=(-32.768,32.768))\n",
    "    test ['X1'] = pd.Series(X1)\n",
    "    test ['X2'] = pd.Series(X2)\n",
    "    true_minimax = np.zeros(test.shape[0])\n",
    "    true_composite = np.zeros(test.shape[0])\n",
    "    for i in range(test.shape[0]):\n",
    "        true_minimax[i] = robust_regularization(test.iloc[i,:])\n",
    "        true_composite[i] = composite_robustness(test.iloc[i,:])\n",
    "    test ['True_Minimax'] = pd.Series(true_minimax)\n",
    "    test ['True_Composite'] = pd.Series(true_composite)\n",
    "    test.to_csv('Test_Data_Sets\\\\'+str(n_obs)+'Samples.csv')\n",
    "    return test\n",
    "\n",
    "''' Check if There are same examples in Test and Train Data Sets'''\n",
    "def check_data_sets(train,test):\n",
    "    C = train.isin(test)\n",
    "    C = pd.DataFrame.sum(C,axis=1)\n",
    "    ids = C.index[C>1]\n",
    "    print ('Total Number of Input Observations present in Test Data : '+str(ids.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMA-ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3_w,6)-aCMA-ES (mu_w=2.0,w_1=63%) in dimension 2 (seed=172920, Sun Mar 31 11:29:44 2019)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1      6 2.060583492128721e+01 1.0e+00 1.22e+01  1e+01  1e+01 0:00.0\n",
      "    2     12 2.029063245203407e+01 1.2e+00 1.23e+01  1e+01  1e+01 0:00.0\n",
      "    3     18 1.906410684945379e+01 1.5e+00 1.02e+01  7e+00  9e+00 0:00.0\n",
      "  100    600 1.603191488399802e+01 9.2e+00 5.41e-05  2e-08  3e-08 0:00.3\n",
      "  167   1002 1.603191486189179e+01 5.4e+00 1.69e-06  7e-12  9e-12 0:00.6\n",
      "termination on tolx=1e-11 (Sun Mar 31 11:29:46 2019)\n",
      "final/bestever f-value = 1.603191e+01 1.603191e+01\n",
      "incumbent solution: [0.29496754290068566, -0.29496754289468163]\n",
      "std deviation: [6.832524668634485e-12, 9.116565438650256e-12]\n",
      "(3_w,6)-aCMA-ES (mu_w=2.0,w_1=63%) in dimension 2 (seed=166936, Sun Mar 31 11:29:46 2019)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1      6 1.958187366784770e+01 1.0e+00 1.28e+01  1e+01  1e+01 0:00.0\n",
      "    2     12 1.898279656791985e+01 1.3e+00 1.13e+01  8e+00  1e+01 0:00.0\n",
      "    3     18 1.639483014046474e+01 1.3e+00 1.24e+01  1e+01  1e+01 0:00.0\n",
      "  100    600 1.731081068927141e+01 3.5e+02 1.10e-06  6e-09  1e-08 0:00.7\n",
      "  120    720 1.731081068928321e+01 1.0e+03 4.00e-08  9e-11  1e-10 0:00.8\n",
      "termination on tolfun=1e-11 (Sun Mar 31 11:29:48 2019)\n",
      "final/bestever f-value = 1.731081e+01 1.530178e+01\n",
      "incumbent solution: [-7.887486988924617, -4.635089254206709]\n",
      "std deviation: [8.741072810175289e-11, 1.353806931128078e-10]\n"
     ]
    }
   ],
   "source": [
    "opt = {'seed': 0 , 'maxfevals': 1e6  }\n",
    "rr = cma.fmin(robust_regularization, 2 * [0] , 16.4 , options=opt  )\n",
    "rc = cma.fmin(composite_robustness, 2 * [0] , 16.4 , options=opt  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xmin for RR :[ 0.29496754 -0.29496754]\n",
      "Fmin for RR :16.031914861891703\n",
      "Xmin for RC :[-3.80869461 -5.22576592]\n",
      "Fmin for RC :15.301781731408404\n"
     ]
    }
   ],
   "source": [
    "print ('Xmin for RR :'+str(rr[0]))\n",
    "print ('Fmin for RR :'+str(rr[1]))\n",
    "print ('Xmin for RC :'+str(rc[0]))\n",
    "print ('Fmin for RC :'+str(rc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLSQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "const = Bounds([-32.768, -32.768], [32.768, 32.768])\n",
    "min_robust = minimize(robust_regularization,(0,0),method='SLSQP',bounds=const)\n",
    "min_compo = minimize(composite_robustness,(0,0),method='SLSQP',bounds=const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 16.936628029225954\n",
       "     jac: array([0.13527513, 0.13527513])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 15\n",
       "     nit: 1\n",
       "    njev: 1\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([-8.7176233e-07, -8.7176233e-07])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 6.753662007025669\n",
       "     jac: array([-0.00060558, -0.00060558])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 16\n",
       "     nit: 4\n",
       "    njev: 4\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([0.00969311, 0.00969311])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_compo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "lhd = pyDOE.lhs(n=2, samples= 1000, criterion='m')\n",
    "X1 = linearscaletransform(lhd[:,0],range_out=(-32.768,32.768))\n",
    "X2 = linearscaletransform(lhd[:,1],range_out=(-32.768,32.768))\n",
    "Data = pd.DataFrame()\n",
    "Data['X1'] = pd.Series(X1)\n",
    "Data['X2'] = pd.Series(X2)\n",
    "Data.to_csv('Optimization_Test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(sys.path[1]+str('\\\\Training_Data_Sets\\\\100Samples.csv')).iloc[:,1:]\n",
    "test = pd.read_csv('Optimization_Test.csv').iloc[:,1:]\n",
    "model_k_m,pred_k_m = Utils.kriging_minimax(train,test.iloc[:,:2])\n",
    "model_k_c,pred_k_c = Utils.kriging_composite(train,test.iloc[:,:2])\n",
    "model_r_m,pred_r_m = Utils.rf_minimax(train,test.iloc[:,:2])\n",
    "model_r_c,pred_r_c = Utils.rf_composite(train,test.iloc[:,:2])\n",
    "model_n_m,pred_n_m = Utils.KNN_minimax(train,test.iloc[:,:2])\n",
    "model_n_c,pred_n_c = Utils.KNN_composite(train,test.iloc[:,:2])\n",
    "model_s_m,pred_s_m = Utils.SVR_minimax(train,test.iloc[:,:2])\n",
    "model_s_c,pred_s_c = Utils.SVR_composite(train,test.iloc[:,:2])\n",
    "model_b_m,pred_b_m = Utils.RBF_minimax(train,test.iloc[:,:2])\n",
    "model_b_c,pred_b_c = Utils.RBF_composite(train,test.iloc[:,:2])\n",
    "train ['X1X2'] = pd.Series( np.array(train.X1) * np.array(train.X2) )\n",
    "train ['X1**2'] = pd.Series ( np.array(train.X1)**2 )\n",
    "train ['X2**2'] = pd.Series ( np.array(train.X2)**2 )\n",
    "f_original = train['Y = F(X1,X2)']\n",
    "robust_original = train['Y = robust_regularization(X1,X2)']\n",
    "composite_original = train ['Y = composite(X1,X2)']\n",
    "del train['Y = F(X1,X2)']\n",
    "del train['Y = robust_regularization(X1,X2)']\n",
    "del train ['Y = composite(X1,X2)']\n",
    "train['Y = F(X1,X2)'] = f_original\n",
    "train['Y = robust_regularization(X1,X2)'] = robust_original\n",
    "train ['Y = composite(X1,X2)'] = composite_original\n",
    "test ['X1X2'] =  pd.Series( np.array(test.X1) * np.array(test.X2) )\n",
    "test ['X1**2'] = pd.Series ( np.array(test.X1)**2 )\n",
    "test ['X2**2'] = pd.Series ( np.array(test.X2)**2 )\n",
    "model_m_m,pred_m_m = Utils.elastic_net_minimax(train,test.iloc[:,:5])\n",
    "model_m_c,pred_m_c = Utils.elastic_net_composite(train,test.iloc[:,:5])\n",
    "del train['X1X2']\n",
    "del train['X1**2']\n",
    "del train['X2**2']\n",
    "del test['X1X2']\n",
    "del test['X1**2']\n",
    "del test['X2**2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using Kriging is : 17.014841059206834\n",
      "At X = :[-1.56407075  0.51378406]\n",
      "RC :  Minimum Using Kriging is : 7.728206585775058\n",
      "At X = :[-1.20453403 -0.04415047]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using Kriging is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_k_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_k_m),:])))\n",
    "print ('RC :  Minimum Using Kriging is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_k_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_k_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using SVR  is : 17.014841059206834\n",
      "At X = :[-1.56407075  0.51378406]\n",
      "RC :  Minimum Using SVR is : 7.709349436319826\n",
      "At X = :[-0.80030553 -0.71519228]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using SVR  is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_s_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_s_m),:])))\n",
    "print ('RC :  Minimum Using SVR is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_s_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_s_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using KNN is : 17.517316929006554\n",
      "At X = :[-3.25609051  1.26503354]\n",
      "RC :  Minimum Using KNN is : 9.208888928118673\n",
      "At X = :[1.95129025 0.67959169]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using KNN is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_n_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_n_m),:])))\n",
    "print ('RC :  Minimum Using KNN is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_n_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_n_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using RF is : 17.975237352254663\n",
      "At X = :[-3.36653792  0.12298411]\n",
      "RC :  Minimum Using RF is : 11.818671344789811\n",
      "At X = :[2.72416023 2.19294009]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using RF is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_r_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_r_m),:])))\n",
    "print ('RC :  Minimum Using RF is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_r_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_r_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using RBFN is : 22.051826676914587\n",
      "At X = :[-32.33262943  32.01916015]\n",
      "RC :  Minimum Using RBFN is : 7.728206585775058\n",
      "At X = :[-1.20453403 -0.04415047]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using RBFN is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_b_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_b_m),:])))\n",
    "print ('RC :  Minimum Using RBFN is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_b_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_b_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using ELN is : 17.38835785798418\n",
      "At X = :[-0.80030553 -0.71519228]\n",
      "RC :  Minimum Using ELN is : 7.709349436319826\n",
      "At X = :[-0.80030553 -0.71519228]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using ELN is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_m_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_m_m),:])))\n",
    "print ('RC :  Minimum Using ELN is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_m_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_m_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
