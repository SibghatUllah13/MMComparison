{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyDOE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Utils \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import namedtuple\n",
    "from matplotlib import cm\n",
    "import cma\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValueRange = namedtuple('ValueRange', ['min', 'max'])\n",
    "\n",
    "def determinerange(values):\n",
    "    \"\"\"Determine the range of values in each dimension\"\"\"\n",
    "    return ValueRange(np.min(values, axis=0), np.max(values, axis=0))\n",
    "\n",
    "\n",
    "def linearscaletransform(values, *, range_in=None, range_out=ValueRange(0, 1), scale_only=False):\n",
    "    \"\"\"Perform a scale transformation of `values`: [range_in] --> [range_out]\"\"\"\n",
    "\n",
    "    if range_in is None:\n",
    "        range_in = determinerange(values)\n",
    "    elif not isinstance(range_in, ValueRange):\n",
    "        range_in = ValueRange(*range_in)\n",
    "\n",
    "    if not isinstance(range_out, ValueRange):\n",
    "        range_out = ValueRange(*range_out)\n",
    "\n",
    "    scale_out = range_out.max - range_out.min\n",
    "    scale_in = range_in.max - range_in.min\n",
    "\n",
    "    if scale_only:\n",
    "        scaled_values = (values / scale_in) * scale_out\n",
    "    else:\n",
    "        scaled_values = (values - range_in.min) / scale_in\n",
    "        scaled_values = (scaled_values * scale_out) + range_out.min\n",
    "\n",
    "    return scaled_values\n",
    "\n",
    "\n",
    "''' Plot the Graph of the Function'''\n",
    "def plot_the_graph(x,y,z,graph_title):\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    ax = Axes3D(fig)\n",
    "    surf = ax.plot_trisurf(x,y,z,cmap=cm.jet, linewidth=0.3,alpha=0.9)\n",
    "    fig.colorbar(surf, shrink=10, aspect=3)\n",
    "    ax.set_xlabel('X1')\n",
    "    ax.set_ylabel('X2')\n",
    "    ax.set_zlabel('Robust(X1,X2)')\n",
    "    plt.title(graph_title)\n",
    "    plt.show()\n",
    "    fig.savefig(graph_title+'.pdf')\n",
    "\n",
    "''' Original Function for Optimization '''\n",
    "def ackley_2D(X):\n",
    "    x1,x2 = X\n",
    "    A = (-20 *  np.exp (-0.2 * np.sqrt(( (x1**2) + (x2**2) ) / (2) ) ) )\n",
    "    B = np.exp (((np.cos(2 * np.pi * x1 ) ) + (np.cos(2 * np.pi * x2 ) ) ) / (2) )\n",
    "    return A - B +20 +np.exp(1)\n",
    "\n",
    "''' Latin HyperCube Sampling Design of Experiment '''\n",
    "def DOE(n_obs):\n",
    "    np.random.seed(0)\n",
    "    lhd = pyDOE.lhs(n=2, samples=n_obs, criterion='m')\n",
    "    X1, X2 = lhd[:,0], lhd[:,1]\n",
    "    return X1,X2\n",
    "\n",
    "\n",
    "'''Robust Regularization based on minimax Principle 5% perturbations'''\n",
    "def robust_regularization(X):\n",
    "    x1,x2 = X\n",
    "    eps = np.linspace(-6.5536,6.5536,2000)\n",
    "    return np.max( ackley_2D([x1+eps,x2+eps]) )\n",
    "\n",
    "''' Robustness based on a composite function of Mean and STd '''\n",
    "def composite_robustness(X):\n",
    "    w=1\n",
    "    x1,x2 = X\n",
    "    np.random.seed(0)\n",
    "    eps = np.random.normal(loc=0.0,scale=1.0922666666666667,size=10000)\n",
    "    sample_points = ackley_2D([x1+eps,x2+eps])\n",
    "    sample_mean = np.mean(sample_points)\n",
    "    variance = np.square(sample_points-sample_mean)\n",
    "    std = np.sqrt(np.mean(variance))\n",
    "    std = np.sqrt(np.mean(variance))\n",
    "    return sample_mean + w * std\n",
    "\n",
    "''' Generate Training Data using LHD along side the Output of the Robust System'''\n",
    "def generate_training_data(n_obs):\n",
    "    X1,X2 = DOE(n_obs)\n",
    "    X1 = linearscaletransform(X1,range_out=(-32.768,32.768))\n",
    "    X2 = linearscaletransform(X2,range_out=(-32.768,32.768))\n",
    "    f_evaluation = ackley_2D([X1,X2])\n",
    "    f_original = np.zeros(X1.shape[0])\n",
    "    minimax_original = np.zeros(X1.shape[0])\n",
    "    composite_original = np.zeros(X1.shape[0])\n",
    "    for i in range(X1.shape[0]):\n",
    "        f_original[i] = ackley_2D([X1[i],X2[i]])\n",
    "        minimax_original[i] = robust_regularization([X1[i],X2[i]])\n",
    "        composite_original[i] = composite_robustness([X1[i],X2[i]])\n",
    "    train = pd.DataFrame()\n",
    "    train['X1'] = pd.Series(X1)\n",
    "    train['X2'] = pd.Series(X2)\n",
    "    train['Y = F(X1,X2)'] = pd.Series(f_original)\n",
    "    train['Y = robust_regularization(X1,X2)'] = pd.Series(minimax_original)\n",
    "    train['Y = composite(X1,X2)'] = pd.Series(composite_original)\n",
    "    train.to_csv('Training_Data_Sets\\\\'+str(n_obs)+'Samples.csv')\n",
    "    return train\n",
    "\n",
    "''' Generate Test Data using LHD along side the Output of the Robust System'''\n",
    "def generate_test_data(n_obs):\n",
    "    test = pd.DataFrame()\n",
    "    np.random.seed(0)\n",
    "    lhd = pyDOE.lhs(n=2, samples=n_obs, criterion='m')\n",
    "    X1 = linearscaletransform(lhd[:,0],range_out=(-32.768,32.768))\n",
    "    X2 = linearscaletransform(lhd[:,1],range_out=(-32.768,32.768))\n",
    "    test ['X1'] = pd.Series(X1)\n",
    "    test ['X2'] = pd.Series(X2)\n",
    "    true_minimax = np.zeros(test.shape[0])\n",
    "    true_composite = np.zeros(test.shape[0])\n",
    "    for i in range(test.shape[0]):\n",
    "        true_minimax[i] = robust_regularization(test.iloc[i,:])\n",
    "        true_composite[i] = composite_robustness(test.iloc[i,:])\n",
    "    test ['True_Minimax'] = pd.Series(true_minimax)\n",
    "    test ['True_Composite'] = pd.Series(true_composite)\n",
    "    test.to_csv('Test_Data_Sets\\\\'+str(n_obs)+'Samples.csv')\n",
    "    return test\n",
    "\n",
    "''' Check if There are same examples in Test and Train Data Sets'''\n",
    "def check_data_sets(train,test):\n",
    "    C = train.isin(test)\n",
    "    C = pd.DataFrame.sum(C,axis=1)\n",
    "    ids = C.index[C>1]\n",
    "    print ('Total Number of Input Observations present in Test Data : '+str(ids.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
