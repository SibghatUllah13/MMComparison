{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyDOE\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import namedtuple\n",
    "from matplotlib import cm\n",
    "from scipy.stats import mannwhitneyu\n",
    "import cma\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pyDOE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats.distributions as dist\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.gaussian_process.kernels import DotProduct\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from collections import namedtuple\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from RBFN import RBFN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Elastic Net Regression for Minimax Robustness'''\n",
    "def elastic_net_minimax(train_data,test_data):\n",
    "    scaler =  MinMaxScaler().fit(np.r_[train_data.iloc[:,:20].values, test_data.values])\n",
    "    regr=ElasticNet(alpha= 0.00936128291725778   ,random_state=0 , l1_ratio= 0.3883883883883884, fit_intercept =True, max_iter=1000,selection='random'\n",
    "                   ).fit(scaler.transform(train_data.iloc[:,:20]), train_data.iloc[:,21])\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = np.array([x[0] , x[1] , x[2], x[3], x[4], x[0] * x[1], x[0] * x[2], x[0] * x[3], x[0] * x[4],\n",
    "                          x[1] * x[2] , x[1] * x[3], x[1] * x[4], x[2] * x[3], x[2] * x[4], x[3] * x[4], x[0] **2 , \n",
    "                          x[1] **2, x[2] **2 , x[3] **2, x[4] **2])\n",
    "            x = np.atleast_2d(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler, regr)\n",
    "\n",
    "''' Elastic Net Regression for Minimax Robustness'''\n",
    "def elastic_net_composite(train_data,test_data):\n",
    "    scaler =  MinMaxScaler().fit(np.r_[train_data.iloc[:,:20].values, test_data.values])\n",
    "    regr=ElasticNet(alpha= 0.009890593823256568      ,random_state=0 , l1_ratio= 0.2552552552552553, fit_intercept =True, max_iter=1000,selection='random'\n",
    "                   ).fit(scaler.transform(train_data.iloc[:,:20]), train_data.iloc[:,-1])\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = np.array([x[0] , x[1] , x[2], x[3], x[4], x[0] * x[1], x[0] * x[2], x[0] * x[3], x[0] * x[4],\n",
    "                          x[1] * x[2] , x[1] * x[3], x[1] * x[4], x[2] * x[3], x[2] * x[4], x[3] * x[4], x[0] **2 , \n",
    "                          x[1] **2, x[2] **2 , x[3] **2, x[4] **2])\n",
    "            x = np.atleast_2d(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler, regr)\n",
    "\n",
    "\n",
    "''' Kriging for Robust Regularization'''\n",
    "def kriging_minimax(train_data,test_data):\n",
    "    kernel =  RBF( 34,(100,57238) )\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:5].values, test_data.values])\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel,n_restarts_optimizer=69,random_state=0,\n",
    "                                   normalize_y=True ).fit(scaler.transform(train_data.iloc[:,:5]), train_data.iloc[:,6])\n",
    "    pred = gpr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, gpr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return gpr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return gpr,pred, predict(scaler,gpr)\n",
    "\n",
    "\n",
    "''' Kriging for Robust Composition'''\n",
    "def kriging_composite(train_data,test_data):\n",
    "    kernel =  RBF( 34,(100,57238) )\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:5].values, test_data.values])\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel,n_restarts_optimizer=69,random_state=0,\n",
    "                                   normalize_y=True ).fit(scaler.transform(train_data.iloc[:,:5]), train_data.iloc[:,-1])\n",
    "    pred = gpr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, gpr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return gpr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return gpr,pred, predict(scaler,gpr)\n",
    "\n",
    "\n",
    "''' Random Forest Implementation for Minimax Robustness'''\n",
    "def rf_minimax(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:5].values, test_data.values])\n",
    "    regr = RandomForestRegressor(random_state=30,n_estimators=85\n",
    "                                ).fit(scaler.transform(train_data.iloc[:,:5]), train_data.iloc[:,6])\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler,regr)\n",
    "\n",
    "''' Random Forest Implementation for Composite Robustness'''\n",
    "def rf_composite(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:5].values, test_data.values])\n",
    "    regr = RandomForestRegressor(random_state=13,n_estimators=36\n",
    "                                ).fit(scaler.transform(train_data.iloc[:,:5]), train_data.iloc[:,-1])\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler,regr)\n",
    "\n",
    "\n",
    "''' KNN Regression Implementation for Minimax Robustness'''\n",
    "def KNN_minimax(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:5].values, test_data.values])\n",
    "    regr = KNeighborsRegressor(n_neighbors=10,weights='distance',algorithm='brute',p=2\n",
    "                               ).fit(scaler.transform(train_data.iloc[:,:5]), train_data.iloc[:,6])\n",
    "\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler,regr)\n",
    "\n",
    "''' KNN Regression Implementation for Composite Robustness'''\n",
    "def KNN_composite(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:5].values, test_data.values])\n",
    "    regr = KNeighborsRegressor(n_neighbors=4,weights='distance',algorithm='brute',p=2\n",
    "                               ).fit(scaler.transform(train_data.iloc[:,:5]), train_data.iloc[:,-1])\n",
    "\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler,regr)\n",
    "\n",
    "''' Support Vector Regression for Robust Regularization'''\n",
    "def SVR_minimax(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:5].values, test_data.values])\n",
    "    gpr = SVR(gamma =  0.465343    ,C =  36.092910, epsilon=0.2,max_iter=1500).fit(\n",
    "        scaler.transform(train_data.iloc[:,:5]), train_data.iloc[:,6])\n",
    "    pred = gpr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, gpr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return gpr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return gpr,pred, predict(scaler,gpr)\n",
    "\n",
    "''' Support Vector Regression for Robust Composition'''\n",
    "def SVR_composite(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:5].values, test_data.values])\n",
    "    gpr = SVR(gamma =  0.061596 ,C = 741.344897, epsilon=0.2,max_iter=1500).fit(\n",
    "        scaler.transform(train_data.iloc[:,:5]), train_data.iloc[:,-1])\n",
    "    pred = gpr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, gpr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return gpr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return gpr,pred, predict(scaler,gpr)\n",
    "\n",
    "\n",
    "''' RBF Network Interpolation for Robust Regularization'''\n",
    "def RBF_minimax(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:5].values, test_data.values])\n",
    "    model = RBFN(hidden_shape=43, sigma= 0.001000)\n",
    "    model.fit(scaler.transform(np.array(train_data.iloc[:,:5])), np.array(train_data.iloc[:,6]))\n",
    "    pred = model.predict(scaler.transform(np.array(test_data)))\n",
    "    def predict(scaler, model):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return model.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return model,pred, predict(scaler,model)\n",
    "\n",
    "''' RBF Network Interpolation for Robust Composition'''\n",
    "def RBF_composite(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:5].values, test_data.values])\n",
    "    model = RBFN(hidden_shape=43, sigma= 0.001000)\n",
    "    model.fit(scaler.transform(np.array(train_data.iloc[:,:5])), np.array(train_data.iloc[:,-1]))\n",
    "    pred = model.predict(scaler.transform(np.array(test_data)))\n",
    "    def predict(scaler, model):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return model.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return model,pred, predict(scaler,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(sys.path[1]+str('\\\\Training_Data_Sets\\\\250Samples.csv')).iloc[:,1:]\n",
    "test = pd.read_csv(sys.path[1]+str('\\\\Test_Data_Sets\\\\375Samples.csv')).iloc[:,1:]\n",
    "model_k_m,pred_k_m, predict_k_m = kriging_minimax(train,test.iloc[:,:5])\n",
    "model_k_c,pred_k_c, predict_k_c = kriging_composite(train,test.iloc[:,:5])\n",
    "model_r_m,pred_r_m, predict_r_m = rf_minimax(train,test.iloc[:,:5])\n",
    "model_r_c,pred_r_c, predict_r_c = rf_composite(train,test.iloc[:,:5])\n",
    "model_n_m,pred_n_m, predict_n_m = KNN_minimax(train,test.iloc[:,:5])\n",
    "model_n_c,pred_n_c , predict_n_c= KNN_composite(train,test.iloc[:,:5])\n",
    "model_s_m,pred_s_m, predict_s_m = SVR_minimax(train,test.iloc[:,:5])\n",
    "model_s_c,pred_s_c, predict_s_c = SVR_composite(train,test.iloc[:,:5])\n",
    "model_b_m,pred_b_m, predict_b_m = RBF_minimax(train,test.iloc[:,:5])\n",
    "model_b_c,pred_b_c, predict_b_c = RBF_composite(train,test.iloc[:,:5])\n",
    "train = create_basis_function_train(train)\n",
    "test = create_basis_function_test(test)\n",
    "model_m_m,pred_m_m, predict_m_m = elastic_net_minimax(train,test.iloc[:,:20])\n",
    "model_m_c,pred_m_c, predict_m_c = elastic_net_composite(train,test.iloc[:,:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = ['Benchmark', 'Kriging' , 'SVM' , 'RBFN' ,  'KNN' , 'RF'  , 'ELN' ]\n",
    "Cols = []\n",
    "for j in range(len(Columns)):\n",
    "    for i in range(1,6):\n",
    "        Cols.append(Columns[j]+'_X'+str(i))\n",
    "        \n",
    "const = Bounds([-32.768, -32.768 , -32.768, -32.768 , -32.768], [32.768, 32.768 , 32.768, 32.768 , 32.768])\n",
    "G1,G2,G3,G4,G5 = DOE(100)\n",
    "G1 = linearscaletransform(G1,range_out=(-32.768,32.768))\n",
    "G2 = linearscaletransform(G2,range_out=(-32.768,32.768))\n",
    "G3 = linearscaletransform(G3,range_out=(-32.768,32.768))\n",
    "G4 = linearscaletransform(G4,range_out=(-32.768,32.768))\n",
    "G5 = linearscaletransform(G5,range_out=(-32.768,32.768))\n",
    "\n",
    "\n",
    "X_Values_RR = np.zeros([100,35])\n",
    "X_Values_RC = np.zeros([100,35])\n",
    "Fun_Eval_RR = np.zeros([100,7])\n",
    "Fun_Eval_RC = np.zeros([100,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLSQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_Values_RR.shape[0]):\n",
    "    min_robust = minimize(robust_regularization,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i]])),method='SLSQP',bounds=const)\n",
    "    min_compo = minimize(composite_robustness,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i]])),method='SLSQP',bounds=const)\n",
    "    min_robust_k = minimize(predict_k_m,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i]])),method='SLSQP',bounds=const)\n",
    "    min_composite_k = minimize(predict_k_c,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i]])),method='SLSQP',bounds=const)\n",
    "    min_robust_s = minimize(predict_s_m,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i]])),method='SLSQP',bounds=const)\n",
    "    min_composite_s = minimize(predict_s_c,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i]])),method='SLSQP',bounds=const)\n",
    "    min_robust_b = minimize(predict_b_m,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i]])),method='SLSQP',bounds=const)\n",
    "    min_composite_b = minimize(predict_b_c,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i]])),method='SLSQP',bounds=const)\n",
    "    min_robust_n = minimize(predict_n_m,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i]])),method='SLSQP',bounds=const)\n",
    "    min_composite_n = minimize(predict_n_c,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i]])),method='SLSQP',bounds=const)\n",
    "    min_robust_r = minimize(predict_r_m,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i]])),method='SLSQP',bounds=const)\n",
    "    min_composite_r = minimize(predict_r_c,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i]])),method='SLSQP',bounds=const)\n",
    "    min_robust_m = minimize(predict_m_m,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i]])),method='SLSQP',bounds=const)\n",
    "    min_composite_m = minimize(predict_m_c,(np.array([G1[i],G2[i],G3[i],G4[i],G5[i]])),method='SLSQP',bounds=const)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    X_Values_RR [i,:] = list(min_robust.x)+list(min_robust_k.x)+list(min_robust_s.x)+list(min_robust_b.x)+list(min_robust_n.x)+list(min_robust_r.x)+list(min_robust_m.x)\n",
    "    \n",
    "    X_Values_RC [i,:] = list(min_compo.x)+list(min_composite_k.x)+list(min_composite_s.x)+list(min_composite_b.x)+list(min_composite_n.x)+list(min_composite_r.x)+list(min_composite_m.x)\n",
    "    \n",
    "    Fun_Eval_RR [i,:] = [min_robust.nfev]+[100,100,100,100,100,100]\n",
    "    \n",
    "    Fun_Eval_RC [i,:] = [min_compo.nfev]+[100,100,100,100,100,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Values_RR = pd.DataFrame(X_Values_RR)\n",
    "X_Values_RR.columns = Cols\n",
    "X_Values_RC = pd.DataFrame(X_Values_RC)\n",
    "X_Values_RC.columns = Cols\n",
    "Fun_Eval_RR = pd.DataFrame(Fun_Eval_RR)\n",
    "Fun_Eval_RR.columns = Columns\n",
    "Fun_Eval_RC = pd.DataFrame(Fun_Eval_RC)\n",
    "Fun_Eval_RC.columns = Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Values_RR = pd.DataFrame(X_Values_RR)\n",
    "X_Values_RR.columns = Cols\n",
    "X_Values_RC = pd.DataFrame(X_Values_RC)\n",
    "X_Values_RC.columns = Cols\n",
    "Fun_Eval_RR = pd.DataFrame(Fun_Eval_RR)\n",
    "Fun_Eval_RR.columns = Columns\n",
    "Fun_Eval_RC = pd.DataFrame(Fun_Eval_RC)\n",
    "Fun_Eval_RC.columns = Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Values_RR.to_csv('Results\\\\X_Values_RR.csv')\n",
    "X_Values_RC.to_csv('Results\\\\X_Values_RC.csv')\n",
    "Fun_Eval_RR.to_csv('Results\\\\Function_Eval_RR.csv')\n",
    "Fun_Eval_RC.to_csv('Results\\\\Function_Eval_RC.csv')\n",
    "RR = pd.read_csv('Results\\\\X_Values_RR.csv').iloc[:,1:]\n",
    "RC = pd.read_csv('Results\\\\X_Values_RC.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bench_Fun_RR = np.zeros(100)\n",
    "Krig_Fun_RR = np.zeros(100)\n",
    "SVM_Fun_RR = np.zeros(100)\n",
    "RBFN_Fun_RR = np.zeros(100)\n",
    "KNN_Fun_RR = np.zeros(100)\n",
    "RF_Fun_RR = np.zeros(100)\n",
    "ELN_Fun_RR = np.zeros(100)\n",
    "for i in range(X_Values_RR.shape[0]):\n",
    "    Bench_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,:5])\n",
    "    Krig_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,5:10])\n",
    "    SVM_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,10:15])\n",
    "    RBFN_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,15:20])\n",
    "    KNN_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,20:25])\n",
    "    RF_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,25:30])\n",
    "    ELN_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,30:35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLSQP\n",
      "ModeResult(mode=array([14.38432767]), count=array([1])) 0.7284895973864732\n",
      "Kriging\n",
      "ModeResult(mode=array([15.70392264]), count=array([1])) 0.7962187809447773\n",
      "SVM\n",
      "ModeResult(mode=array([19.90610132]), count=array([1])) 0.0742712614280871\n",
      "RBFN\n",
      "ModeResult(mode=array([15.7001137]), count=array([1])) 0.8519675176020145\n",
      "KNN\n",
      "ModeResult(mode=array([14.41720027]), count=array([1])) 1.344759540632086\n",
      "RF\n",
      "ModeResult(mode=array([15.65671085]), count=array([1])) 0.8316353690257411\n",
      "ELN\n",
      "ModeResult(mode=array([21.72577347]), count=array([24])) 0.0756146639080688\n"
     ]
    }
   ],
   "source": [
    "print ('SLSQP')\n",
    "print (stats.mode(Bench_Fun_RR) , np.std(Bench_Fun_RR))\n",
    "print ('Kriging')\n",
    "print (stats.mode(Krig_Fun_RR) , np.std(Krig_Fun_RR))\n",
    "print ('SVM')\n",
    "print (stats.mode(SVM_Fun_RR) , np.std(SVM_Fun_RR))\n",
    "print ('RBFN')\n",
    "print (stats.mode(RBFN_Fun_RR) , np.std(RBFN_Fun_RR))\n",
    "print ('KNN')\n",
    "print (stats.mode(KNN_Fun_RR) , np.std(KNN_Fun_RR))\n",
    "print ('RF')\n",
    "print (stats.mode(RF_Fun_RR) , np.std(RF_Fun_RR))\n",
    "print ('ELN')\n",
    "print (stats.mode(ELN_Fun_RR) , np.std(ELN_Fun_RR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bench_Fun_RC = np.zeros(100)\n",
    "Krig_Fun_RC = np.zeros(100)\n",
    "SVM_Fun_RC = np.zeros(100)\n",
    "RBFN_Fun_RC = np.zeros(100)\n",
    "KNN_Fun_RC = np.zeros(100)\n",
    "RF_Fun_RC = np.zeros(100)\n",
    "ELN_Fun_RC = np.zeros(100)\n",
    "for i in range(X_Values_RC.shape[0]):\n",
    "    Bench_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,:5])\n",
    "    Krig_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,5:10])\n",
    "    SVM_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,10:15])\n",
    "    RBFN_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,15:20])\n",
    "    KNN_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,20:25])\n",
    "    RF_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,25:30])\n",
    "    ELN_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,30:35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLSQP\n",
      "ModeResult(mode=array([6.75360841]), count=array([1])) 4.832670515412075\n",
      "Kriging\n",
      "ModeResult(mode=array([18.57106009]), count=array([1])) 0.66851192995125\n",
      "SVM\n",
      "ModeResult(mode=array([8.93567662]), count=array([1])) 1.6477395324533983\n",
      "RBFN\n",
      "ModeResult(mode=array([18.40991114]), count=array([1])) 0.680983976738602\n",
      "KNN\n",
      "ModeResult(mode=array([14.06324631]), count=array([1])) 1.8110754846151198\n",
      "RF\n",
      "ModeResult(mode=array([18.64221319]), count=array([1])) 0.6668319345761311\n",
      "ELN\n",
      "ModeResult(mode=array([21.62495811]), count=array([1])) 0.09350496252763972\n"
     ]
    }
   ],
   "source": [
    "print ('SLSQP')\n",
    "print (stats.mode(Bench_Fun_RC) , np.std(Bench_Fun_RC))\n",
    "print ('Kriging')\n",
    "print (stats.mode(Krig_Fun_RC) , np.std(Krig_Fun_RC))\n",
    "print ('SVM')\n",
    "print (stats.mode(SVM_Fun_RC) , np.std(SVM_Fun_RC))\n",
    "print ('RBFN')\n",
    "print (stats.mode(RBFN_Fun_RC) , np.std(RBFN_Fun_RC))\n",
    "print ('KNN')\n",
    "print (stats.mode(KNN_Fun_RC) , np.std(KNN_Fun_RC))\n",
    "print ('RF')\n",
    "print (stats.mode(RF_Fun_RC) , np.std(RF_Fun_RC))\n",
    "print ('ELN')\n",
    "print (stats.mode(ELN_Fun_RC) , np.std(ELN_Fun_RC))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
