{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyDOE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Utils \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import namedtuple\n",
    "from matplotlib import cm\n",
    "import cma\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValueRange = namedtuple('ValueRange', ['min', 'max'])\n",
    "\n",
    "def determinerange(values):\n",
    "    \"\"\"Determine the range of values in each dimension\"\"\"\n",
    "    return ValueRange(np.min(values, axis=0), np.max(values, axis=0))\n",
    "\n",
    "\n",
    "def linearscaletransform(values, *, range_in=None, range_out=ValueRange(0, 1), scale_only=False):\n",
    "    \"\"\"Perform a scale transformation of `values`: [range_in] --> [range_out]\"\"\"\n",
    "\n",
    "    if range_in is None:\n",
    "        range_in = determinerange(values)\n",
    "    elif not isinstance(range_in, ValueRange):\n",
    "        range_in = ValueRange(*range_in)\n",
    "\n",
    "    if not isinstance(range_out, ValueRange):\n",
    "        range_out = ValueRange(*range_out)\n",
    "\n",
    "    scale_out = range_out.max - range_out.min\n",
    "    scale_in = range_in.max - range_in.min\n",
    "\n",
    "    if scale_only:\n",
    "        scaled_values = (values / scale_in) * scale_out\n",
    "    else:\n",
    "        scaled_values = (values - range_in.min) / scale_in\n",
    "        scaled_values = (scaled_values * scale_out) + range_out.min\n",
    "\n",
    "    return scaled_values\n",
    "\n",
    "\n",
    "''' Original Function for Optimization '''\n",
    "def Sphere_5D(X):\n",
    "    X = np.array(X)\n",
    "    return np.sum(X**2)\n",
    "\n",
    "''' Latin HyperCube Sampling Design of Experiment '''\n",
    "def DOE(n_obs):\n",
    "    np.random.seed(0)\n",
    "    lhd = pyDOE.lhs(n=5, samples=n_obs, criterion='m')\n",
    "    X1,X2,X3,X4,X5 = lhd[:,0],lhd[:,1],lhd[:,2],lhd[:,3],lhd[:,4]\n",
    "    return X1,X2,X3,X4,X5\n",
    "\n",
    "\n",
    "'''Robust Regularization based on minimax Principle'''\n",
    "def robust_regularization(X):\n",
    "    x1,x2,x3,x4,x5 = X\n",
    "    eps = np.linspace(-1.0,1.0,1000)\n",
    "    result = np.zeros(eps.shape[0])\n",
    "    for i in range(eps.shape[0]):\n",
    "        result[i]= Sphere_5D(np.array([x1+eps[i],x2+eps[i],x3+eps[i],x4+eps[i],x5+eps[i]]))\n",
    "    return np.max(result[i])\n",
    "\n",
    "''' Robustness based on a composite function of Mean and STd '''\n",
    "def composite_robustness(X):\n",
    "    w=1\n",
    "    x1,x2,x3,x4,x5 = X\n",
    "    np.random.seed(0)\n",
    "    eps = np.random.normal(loc=0.0,scale=0.166,size=10000)\n",
    "    sample_points = np.zeros(eps.shape[0])\n",
    "    for i in range(eps.shape[0]):\n",
    "        sample_points[i]= Sphere_5D(np.array([x1+eps[i],x2+eps[i],x3+eps[i],x4+eps[i],x5+eps[i]]))\n",
    "    sample_mean = np.mean(sample_points)\n",
    "    variance = np.square(sample_points-sample_mean)\n",
    "    std = np.sqrt(np.mean(variance))\n",
    "    std = np.sqrt(np.mean(variance))\n",
    "    return sample_mean + w * std\n",
    "\n",
    "''' Generate Training Data using LHD along side the Output of the Robust System'''\n",
    "def generate_training_data(n_obs):\n",
    "    X1,X2,X3,X4,X5 = DOE(n_obs)\n",
    "    X1 = linearscaletransform(X1,range_out=(-5,5))\n",
    "    X2 = linearscaletransform(X2,range_out=(-5,5))\n",
    "    X3 = linearscaletransform(X3,range_out=(-5,5))\n",
    "    X4 = linearscaletransform(X4,range_out=(-5,5))\n",
    "    X5 = linearscaletransform(X5,range_out=(-5,5))\n",
    "    f_evaluation = np.zeros(X1.shape[0])\n",
    "    for i in range(X1.shape[0]):\n",
    "        f_evaluation [i] = Sphere_5D(np.array([X1[i],X2[i],X3[i],X4[i],X5[i]]))\n",
    "    f_original = np.zeros(X1.shape[0])\n",
    "    minimax_original = np.zeros(X1.shape[0])\n",
    "    composite_original = np.zeros(X1.shape[0])\n",
    "    for i in range(X1.shape[0]):\n",
    "        f_original[i] = Sphere_5D(np.array([X1[i],X2[i],X3[i],X4[i],X5[i]]))\n",
    "        minimax_original[i] = robust_regularization(np.array([X1[i],X2[i],X3[i],X4[i],X5[i]]))\n",
    "        composite_original[i] = composite_robustness(np.array([X1[i],X2[i],X3[i],X4[i],X5[i]]))\n",
    "    train = pd.DataFrame()\n",
    "    train['X1'] = pd.Series(X1)\n",
    "    train['X2'] = pd.Series(X2)\n",
    "    train['X3'] = pd.Series(X3)\n",
    "    train['X4'] = pd.Series(X4)\n",
    "    train['X5'] = pd.Series(X5)\n",
    "    train['Y = F(X1,X2)'] = pd.Series(f_original)\n",
    "    train['Y = robust_regularization(X1,X2)'] = pd.Series(minimax_original)\n",
    "    train['Y = composite(X1,X2)'] = pd.Series(composite_original)\n",
    "    train.to_csv('Training_Data_Sets\\\\'+str(n_obs)+'Samples.csv')\n",
    "    return train\n",
    "\n",
    "''' Generate Test Data using LHD along side the Output of the Robust System'''\n",
    "def generate_test_data(n_obs):\n",
    "    test = pd.DataFrame()\n",
    "    X = pyDOE.lhs(n=5, samples=n_obs, criterion='m')\n",
    "    for i in range(X.shape[1]):\n",
    "        X[:,i] = linearscaletransform(X[:,i],range_out=(-5,5))\n",
    "        test['X'+str(i+1)] = pd.Series(X[:,i])\n",
    "    true_minimax = np.zeros(X.shape[0])\n",
    "    true_composite = np.zeros(X.shape[0])\n",
    "    for i in range(X.shape[0]):\n",
    "        true_minimax[i] = robust_regularization(X[i,:])\n",
    "        true_composite[i] = composite_robustness(X[i,:])\n",
    "    test ['True_Minimax'] = pd.Series(true_minimax)\n",
    "    test ['True_Composite'] = pd.Series(true_composite)\n",
    "    test.to_csv('Test_Data_Sets\\\\'+str(n_obs)+'Samples.csv')\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 5\n",
    "multiple = [5,10,15,20,25,30,35,40,45,50]\n",
    "for i in range(len(multiple)):\n",
    "    train = generate_training_data(dim * multiple[i])\n",
    "test = generate_test_data(dim * 75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
