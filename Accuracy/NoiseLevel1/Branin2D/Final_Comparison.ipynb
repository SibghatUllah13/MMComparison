{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyDOE\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import namedtuple\n",
    "from matplotlib import cm\n",
    "from scipy.stats import mannwhitneyu\n",
    "import cma\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pyDOE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats.distributions as dist\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.gaussian_process.kernels import DotProduct\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from collections import namedtuple\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from RBFN import RBFN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValueRange = namedtuple('ValueRange', ['min', 'max'])\n",
    "\n",
    "def determinerange(values):\n",
    "    \"\"\"Determine the range of values in each dimension\"\"\"\n",
    "    return ValueRange(np.min(values, axis=0), np.max(values, axis=0))\n",
    "\n",
    "\n",
    "def linearscaletransform(values, *, range_in=None, range_out=ValueRange(0, 1), scale_only=False):\n",
    "    \"\"\"Perform a scale transformation of `values`: [range_in] --> [range_out]\"\"\"\n",
    "\n",
    "    if range_in is None:\n",
    "        range_in = determinerange(values)\n",
    "    elif not isinstance(range_in, ValueRange):\n",
    "        range_in = ValueRange(*range_in)\n",
    "\n",
    "    if not isinstance(range_out, ValueRange):\n",
    "        range_out = ValueRange(*range_out)\n",
    "\n",
    "    scale_out = range_out.max - range_out.min\n",
    "    scale_in = range_in.max - range_in.min\n",
    "\n",
    "    if scale_only:\n",
    "        scaled_values = (values / scale_in) * scale_out\n",
    "    else:\n",
    "        scaled_values = (values - range_in.min) / scale_in\n",
    "        scaled_values = (scaled_values * scale_out) + range_out.min\n",
    "\n",
    "    return scaled_values\n",
    "\n",
    "\n",
    "''' Plot the Graph of the Function'''\n",
    "def plot_the_graph(x,y,z,graph_title):\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    ax = Axes3D(fig)\n",
    "    surf = ax.plot_trisurf(x,y,z,cmap=cm.jet, linewidth=0.3,alpha=0.9)\n",
    "    fig.colorbar(surf, shrink=10, aspect=3)\n",
    "    ax.set_xlabel('X1')\n",
    "    ax.set_ylabel('X2')\n",
    "    ax.set_zlabel('Robust(X1,X2)')\n",
    "    plt.title(graph_title)\n",
    "    plt.show()\n",
    "    fig.savefig(graph_title+'.pdf')\n",
    "\n",
    "''' Branin Test Example  '''\n",
    "def branin_test_example(X):\n",
    "    x,z = X\n",
    "    A = (z) - ((5.1) / (4 * np.square(np.pi))) * (x **2) + (( (5)/(np.pi) ) * (x) ) - (6)\n",
    "    B = (10 * ((1) - ((1) / (8 * np.pi) )) ) * (np.cos(x))\n",
    "    return np.square(A) + B + 10\n",
    "\n",
    "\n",
    "''' Latin HyperCube Sampling Design of Experiment '''\n",
    "def DOE(n_obs):\n",
    "    np.random.seed(0)\n",
    "    lhd = pyDOE.lhs(n=2, samples=n_obs, criterion='m')\n",
    "    X1, X2 = lhd[:,0], lhd[:,1]\n",
    "    return X1,X2\n",
    "\n",
    "\n",
    "'''Robust Regularization based on minimax Principle 5% perturbations'''\n",
    "def robust_regularization(X):\n",
    "    x1,x2 = X\n",
    "    eps = np.linspace(-0.75,0.75,1000)\n",
    "    return np.max( branin_test_example([x1+eps,x2+eps]) )\n",
    "\n",
    "''' Robustness based on a composite function of Mean and STd '''\n",
    "def composite_robustness(X):\n",
    "    w=1\n",
    "    x1,x2 = X\n",
    "    np.random.seed(0)\n",
    "    eps = np.random.normal(loc=0.0,scale=0.125,size=10000)\n",
    "    sample_points = branin_test_example([x1+eps,x2+eps])\n",
    "    sample_mean = np.mean(sample_points)\n",
    "    variance = np.square(sample_points-sample_mean)\n",
    "    std = np.sqrt(np.mean(variance))\n",
    "    std = np.sqrt(np.mean(variance))\n",
    "    return sample_mean + w * std\n",
    "\n",
    "''' Generate Training Data using LHD along side the Output of the Robust System'''\n",
    "def generate_training_data(n_obs):\n",
    "    X1,X2 = DOE(n_obs)\n",
    "    X1 = linearscaletransform(X1,range_out=(-5,10))\n",
    "    X2 = linearscaletransform(X2,range_out=(0,15))\n",
    "    f_evaluation = branin_test_example([X1,X2])\n",
    "    f_original = np.zeros(X1.shape[0])\n",
    "    minimax_original = np.zeros(X1.shape[0])\n",
    "    composite_original = np.zeros(X1.shape[0])\n",
    "    for i in range(X1.shape[0]):\n",
    "        f_original[i] = branin_test_example([X1[i],X2[i]])\n",
    "        minimax_original[i] = robust_regularization([X1[i],X2[i]])\n",
    "        composite_original[i] = composite_robustness([X1[i],X2[i]])\n",
    "    train = pd.DataFrame()\n",
    "    train['X1'] = pd.Series(X1)\n",
    "    train['X2'] = pd.Series(X2)\n",
    "    train['Y = F(X1,X2)'] = pd.Series(f_original)\n",
    "    train['Y = robust_regularization(X1,X2)'] = pd.Series(minimax_original)\n",
    "    train['Y = composite(X1,X2)'] = pd.Series(composite_original)\n",
    "    train.to_csv('Training_Data_Sets\\\\'+str(n_obs)+'Samples.csv')\n",
    "    return train\n",
    "\n",
    "''' Generate Test Data using LHD along side the Output of the Robust System'''\n",
    "def generate_test_data(n_obs):\n",
    "    test = pd.DataFrame()\n",
    "    np.random.seed(0)\n",
    "    lhd = pyDOE.lhs(n=2, samples=n_obs, criterion='m')\n",
    "    X1 = linearscaletransform(lhd[:,0],range_out=(-5,10))\n",
    "    X2 = linearscaletransform(lhd[:,1],range_out=(0,15))\n",
    "    test ['X1'] = pd.Series(X1)\n",
    "    test ['X2'] = pd.Series(X2)\n",
    "    true_minimax = np.zeros(test.shape[0])\n",
    "    true_composite = np.zeros(test.shape[0])\n",
    "    for i in range(test.shape[0]):\n",
    "        true_minimax[i] = robust_regularization(test.iloc[i,:])\n",
    "        true_composite[i] = composite_robustness(test.iloc[i,:])\n",
    "    test ['True_Minimax'] = pd.Series(true_minimax)\n",
    "    test ['True_Composite'] = pd.Series(true_composite)\n",
    "    test.to_csv('Test_Data_Sets\\\\'+str(n_obs)+'Samples.csv')\n",
    "    return test\n",
    "\n",
    "''' Check if There are same examples in Test and Train Data Sets'''\n",
    "def check_data_sets(train,test):\n",
    "    C = train.isin(test)\n",
    "    C = pd.DataFrame.sum(C,axis=1)\n",
    "    ids = C.index[C>1]\n",
    "    print ('Total Number of Input Observations present in Test Data : '+str(ids.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Elastic Net Regression for Minimax Robustness'''\n",
    "def elastic_net_minimax(train_data,test_data):\n",
    "    scaler =  MinMaxScaler().fit(np.r_[train_data.iloc[:,:5].values, test_data.values])\n",
    "    regr=ElasticNet(alpha= 0.03471316333696191   ,random_state=0 , l1_ratio= 0.0, fit_intercept =True, max_iter=1000,selection='random'\n",
    "                   ).fit(scaler.transform(train_data.iloc[:,:5]), train_data.iloc[:,6])\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = np.array([x[0] , x[1] , x[0] * x[1] , x[0] **2 , x[1] **2])\n",
    "            x = np.atleast_2d(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler, regr)\n",
    "\n",
    "''' Elastic Net Regression for Minimax Robustness'''\n",
    "def elastic_net_composite(train_data,test_data):\n",
    "    scaler =  MinMaxScaler().fit(np.r_[train_data.iloc[:,:5].values, test_data.values])\n",
    "    regr=ElasticNet(alpha= 0.03562626988750126  ,random_state=0 , l1_ratio= 0.0, fit_intercept =True, max_iter=1000,selection='random'\n",
    "                   ).fit(scaler.transform(train_data.iloc[:,:5]), train_data.iloc[:,-1])\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = np.array([x[0] , x[1] , x[0] * x[1] , x[0] **2 , x[1] **2])\n",
    "            x = np.atleast_2d(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler, regr)\n",
    "\n",
    "\n",
    "''' Kriging for Robust Regularization'''\n",
    "def kriging_minimax(train_data,test_data):\n",
    "    kernel =  RBF(78, (2, 75065))\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:2].values, test_data.values])\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel,n_restarts_optimizer=89,random_state=0,\n",
    "                                   normalize_y=True ).fit(scaler.transform(train_data.iloc[:,:2]), train_data.iloc[:,3])\n",
    "    pred = gpr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, gpr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return gpr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return gpr,pred, predict(scaler,gpr)\n",
    "\n",
    "\n",
    "''' Kriging for Robust Composition'''\n",
    "def kriging_composite(train_data,test_data):\n",
    "    kernel =  RBF(45, (1, 14296))\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:2].values, test_data.values])\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel,n_restarts_optimizer=93,random_state=0,\n",
    "                                   normalize_y=True ).fit(scaler.transform(train_data.iloc[:,:2]), train_data.iloc[:,-1])\n",
    "    pred = gpr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, gpr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return gpr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return gpr,pred, predict(scaler,gpr)\n",
    "\n",
    "\n",
    "''' Random Forest Implementation for Minimax Robustness'''\n",
    "def rf_minimax(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:2].values, test_data.values])\n",
    "    regr = RandomForestRegressor(random_state=42,n_estimators=6\n",
    "                                ).fit(scaler.transform(train_data.iloc[:,:2]), train_data.iloc[:,3])\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler,regr)\n",
    "\n",
    "''' Random Forest Implementation for Composite Robustness'''\n",
    "def rf_composite(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:2].values, test_data.values])\n",
    "    regr = RandomForestRegressor(random_state=31,n_estimators=5\n",
    "                                ).fit(scaler.transform(train_data.iloc[:,:2]), train_data.iloc[:,-1])\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler,regr)\n",
    "\n",
    "\n",
    "''' KNN Regression Implementation for Minimax Robustness'''\n",
    "def KNN_minimax(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:2].values, test_data.values])\n",
    "    regr = KNeighborsRegressor(n_neighbors=3,weights='distance',algorithm='brute',p=2\n",
    "                               ).fit(scaler.transform(train_data.iloc[:,:2]), train_data.iloc[:,3])\n",
    "\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler,regr)\n",
    "\n",
    "''' KNN Regression Implementation for Composite Robustness'''\n",
    "def KNN_composite(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:2].values, test_data.values])\n",
    "    regr = KNeighborsRegressor(n_neighbors=2,weights='distance',algorithm='brute',p=2\n",
    "                               ).fit(scaler.transform(train_data.iloc[:,:2]), train_data.iloc[:,-1])\n",
    "\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, regr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return regr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return regr,pred, predict(scaler,regr)\n",
    "\n",
    "''' Support Vector Regression for Robust Regularization'''\n",
    "def SVR_minimax(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:2].values, test_data.values])\n",
    "    gpr = SVR(gamma =  2.311373    ,C =  651.399134, epsilon=0.2,max_iter=1500).fit(\n",
    "        scaler.transform(train_data.iloc[:,:2]), train_data.iloc[:,3])\n",
    "    pred = gpr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, gpr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return gpr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return gpr,pred, predict(scaler,gpr)\n",
    "\n",
    "''' Support Vector Regression for Robust Composition'''\n",
    "def SVR_composite(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:2].values, test_data.values])\n",
    "    gpr = SVR(gamma =  0.963224,C = 606.227521, epsilon=0.2,max_iter=1500).fit(\n",
    "        scaler.transform(train_data.iloc[:,:2]), train_data.iloc[:,-1])\n",
    "    pred = gpr.predict(scaler.transform(test_data))\n",
    "    def predict(scaler, gpr):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return gpr.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return gpr,pred, predict(scaler,gpr)\n",
    "\n",
    "\n",
    "''' RBF Network Interpolation for Robust Regularization'''\n",
    "def RBF_minimax(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:2].values, test_data.values])\n",
    "    model = RBFN(hidden_shape=68, sigma= 1.469632)\n",
    "    model.fit(scaler.transform(np.array(train_data.iloc[:,:2])), np.array(train_data.iloc[:,3]))\n",
    "    pred = model.predict(scaler.transform(np.array(test_data)))\n",
    "    def predict(scaler, model):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return model.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return model,pred, predict(scaler,model)\n",
    "\n",
    "''' RBF Network Interpolation for Robust Composition'''\n",
    "def RBF_composite(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:2].values, test_data.values])\n",
    "    model = RBFN(hidden_shape=68, sigma= 1.469632)\n",
    "    model.fit(scaler.transform(np.array(train_data.iloc[:,:2])), np.array(train_data.iloc[:,-1]))\n",
    "    pred = model.predict(scaler.transform(np.array(test_data)))\n",
    "    def predict(scaler, model):\n",
    "        def __predict__(x):\n",
    "            x = np.atleast_2d(x)\n",
    "            return model.predict(scaler.transform(x))\n",
    "        return __predict__\n",
    "    return model,pred, predict(scaler,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(sys.path[1]+str('\\\\Training_Data_Sets\\\\100Samples.csv')).iloc[:,1:]\n",
    "test = pd.read_csv('Optimization_Test.csv').iloc[:,1:]\n",
    "model_k_m,pred_k_m, predict_k_m = kriging_minimax(train,test.iloc[:,:2])\n",
    "model_k_c,pred_k_c, predict_k_c = kriging_composite(train,test.iloc[:,:2])\n",
    "model_r_m,pred_r_m, predict_r_m = rf_minimax(train,test.iloc[:,:2])\n",
    "model_r_c,pred_r_c, predict_r_c = rf_composite(train,test.iloc[:,:2])\n",
    "model_n_m,pred_n_m, predict_n_m = KNN_minimax(train,test.iloc[:,:2])\n",
    "model_n_c,pred_n_c , predict_n_c= KNN_composite(train,test.iloc[:,:2])\n",
    "model_s_m,pred_s_m, predict_s_m = SVR_minimax(train,test.iloc[:,:2])\n",
    "model_s_c,pred_s_c, predict_s_c = SVR_composite(train,test.iloc[:,:2])\n",
    "model_b_m,pred_b_m, predict_b_m = RBF_minimax(train,test.iloc[:,:2])\n",
    "model_b_c,pred_b_c, predict_b_c = RBF_composite(train,test.iloc[:,:2])\n",
    "train ['X1X2'] = pd.Series( np.array(train.X1) * np.array(train.X2) )\n",
    "train ['X1**2'] = pd.Series ( np.array(train.X1)**2 )\n",
    "train ['X2**2'] = pd.Series ( np.array(train.X2)**2 )\n",
    "f_original = train['Y = F(X1,X2)']\n",
    "robust_original = train['Y = robust_regularization(X1,X2)']\n",
    "composite_original = train ['Y = composite(X1,X2)']\n",
    "del train['Y = F(X1,X2)']\n",
    "del train['Y = robust_regularization(X1,X2)']\n",
    "del train ['Y = composite(X1,X2)']\n",
    "train['Y = F(X1,X2)'] = f_original\n",
    "train['Y = robust_regularization(X1,X2)'] = robust_original\n",
    "train ['Y = composite(X1,X2)'] = composite_original\n",
    "test ['X1X2'] =  pd.Series( np.array(test.X1) * np.array(test.X2) )\n",
    "test ['X1**2'] = pd.Series ( np.array(test.X1)**2 )\n",
    "test ['X2**2'] = pd.Series ( np.array(test.X2)**2 )\n",
    "model_m_m,pred_m_m, predict_m_m = elastic_net_minimax(train,test.iloc[:,:5])\n",
    "model_m_c,pred_m_c, predict_m_c = elastic_net_composite(train,test.iloc[:,:5])\n",
    "del train['X1X2']\n",
    "del train['X1**2']\n",
    "del train['X2**2']\n",
    "del test['X1X2']\n",
    "del test['X1**2']\n",
    "del test['X2**2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = ['Benchmark', 'Kriging' , 'SVM' , 'RBFN' ,  'KNN' , 'RF'  , 'ELN' ]\n",
    "Cols = []\n",
    "for j in range(len(Columns)):\n",
    "    for i in range(1,3):\n",
    "        Cols.append(Columns[j]+'_X'+str(i))\n",
    "        \n",
    "const = Bounds([-5, 0], [10, 15])\n",
    "G1,G2 = DOE(100)\n",
    "G1 = linearscaletransform(G1,range_out=(-5,10))\n",
    "G2 = linearscaletransform(G2,range_out=(0,15))\n",
    "\n",
    "\n",
    "X_Values_RR = np.zeros([100,14])\n",
    "X_Values_RC = np.zeros([100,14])\n",
    "Fun_Eval_RR = np.zeros([100,7])\n",
    "Fun_Eval_RC = np.zeros([100,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLSQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_Values_RR.shape[0]):\n",
    "    min_robust = minimize(robust_regularization,(np.array([G1[i],G2[i]])),method='SLSQP',bounds=const)\n",
    "    min_compo = minimize(composite_robustness,(np.array([G1[i],G2[i]])),method='SLSQP',bounds=const)\n",
    "    min_robust_k = minimize(predict_k_m,(np.array([G1[i],G2[i]])),method='SLSQP',bounds=const)\n",
    "    min_composite_k = minimize(predict_k_c,(np.array([G1[i],G2[i]])),method='SLSQP',bounds=const)\n",
    "    min_robust_s = minimize(predict_s_m,(np.array([G1[i],G2[i]])),method='SLSQP',bounds=const)\n",
    "    min_composite_s = minimize(predict_s_c,(np.array([G1[i],G2[i]])),method='SLSQP',bounds=const)\n",
    "    min_robust_b = minimize(predict_b_m,(np.array([G1[i],G2[i]])),method='SLSQP',bounds=const)\n",
    "    min_composite_b = minimize(predict_b_c,(np.array([G1[i],G2[i]])),method='SLSQP',bounds=const)\n",
    "    min_robust_n = minimize(predict_n_m,(np.array([G1[i],G2[i]])),method='SLSQP',bounds=const)\n",
    "    min_composite_n = minimize(predict_n_c,(np.array([G1[i],G2[i]])),method='SLSQP',bounds=const)\n",
    "    min_robust_r = minimize(predict_r_m,(np.array([G1[i],G2[i]])),method='SLSQP',bounds=const)\n",
    "    min_composite_r = minimize(predict_r_c,(np.array([G1[i],G2[i]])),method='SLSQP',bounds=const)\n",
    "    min_robust_m = minimize(predict_m_m,(np.array([G1[i],G2[i]])),method='SLSQP',bounds=const)\n",
    "    min_composite_m = minimize(predict_m_c,(np.array([G1[i],G2[i]])),method='SLSQP',bounds=const)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    X_Values_RR [i,:] = list(min_robust.x)+list(min_robust_k.x)+list(min_robust_s.x)+list(min_robust_b.x)+list(min_robust_n.x)+list(min_robust_r.x)+list(min_robust_m.x)\n",
    "    \n",
    "    X_Values_RC [i,:] = list(min_compo.x)+list(min_composite_k.x)+list(min_composite_s.x)+list(min_composite_b.x)+list(min_composite_n.x)+list(min_composite_r.x)+list(min_composite_m.x)\n",
    "    \n",
    "    Fun_Eval_RR [i,:] = [min_robust.nfev]+[100,100,100,100,100,100]\n",
    "    \n",
    "    Fun_Eval_RC [i,:] = [min_compo.nfev]+[100,100,100,100,100,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Values_RR = pd.DataFrame(X_Values_RR)\n",
    "X_Values_RR.columns = Cols\n",
    "X_Values_RC = pd.DataFrame(X_Values_RC)\n",
    "X_Values_RC.columns = Cols\n",
    "Fun_Eval_RR = pd.DataFrame(Fun_Eval_RR)\n",
    "Fun_Eval_RR.columns = Columns\n",
    "Fun_Eval_RC = pd.DataFrame(Fun_Eval_RC)\n",
    "Fun_Eval_RC.columns = Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Values_RR = pd.DataFrame(X_Values_RR)\n",
    "X_Values_RR.columns = Cols\n",
    "X_Values_RC = pd.DataFrame(X_Values_RC)\n",
    "X_Values_RC.columns = Cols\n",
    "Fun_Eval_RR = pd.DataFrame(Fun_Eval_RR)\n",
    "Fun_Eval_RR.columns = Columns\n",
    "Fun_Eval_RC = pd.DataFrame(Fun_Eval_RC)\n",
    "Fun_Eval_RC.columns = Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Values_RR.to_csv('Results\\\\X_Values_RR.csv')\n",
    "X_Values_RC.to_csv('Results\\\\X_Values_RC.csv')\n",
    "Fun_Eval_RR.to_csv('Results\\\\Function_Eval_RR.csv')\n",
    "Fun_Eval_RC.to_csv('Results\\\\Function_Eval_RC.csv')\n",
    "RR = pd.read_csv('Results\\\\X_Values_RR.csv').iloc[:,1:]\n",
    "RC = pd.read_csv('Results\\\\X_Values_RC.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bench_Fun_RR = np.zeros(100)\n",
    "Krig_Fun_RR = np.zeros(100)\n",
    "SVM_Fun_RR = np.zeros(100)\n",
    "RBFN_Fun_RR = np.zeros(100)\n",
    "KNN_Fun_RR = np.zeros(100)\n",
    "RF_Fun_RR = np.zeros(100)\n",
    "ELN_Fun_RR = np.zeros(100)\n",
    "for i in range(X_Values_RR.shape[0]):\n",
    "    Bench_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,:2])\n",
    "    Krig_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,2:4])\n",
    "    SVM_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,4:6])\n",
    "    RBFN_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,6:8])\n",
    "    KNN_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,8:10])\n",
    "    RF_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,10:12])\n",
    "    ELN_Fun_RR [i] = robust_regularization(X_Values_RR.iloc[i,12:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLSQP\n",
      "ModeResult(mode=array([2.98801356]), count=array([1])) 2.507538081362997\n",
      "Kriging\n",
      "ModeResult(mode=array([5.58386601]), count=array([1])) 63.885873796683875\n",
      "SVM\n",
      "ModeResult(mode=array([8.60577697]), count=array([1])) 2.5112630262448628\n",
      "RBFN\n",
      "ModeResult(mode=array([5.51854611]), count=array([1])) 63.685317784486585\n",
      "KNN\n",
      "ModeResult(mode=array([5.72607585]), count=array([1])) 52.066389958444155\n",
      "RF\n",
      "ModeResult(mode=array([5.72608917]), count=array([1])) 63.920402713192466\n",
      "ELN\n",
      "ModeResult(mode=array([17.08883032]), count=array([42])) 1.6067237221187526e-10\n"
     ]
    }
   ],
   "source": [
    "print ('SLSQP')\n",
    "print (stats.mode(Bench_Fun_RR) , np.std(Bench_Fun_RR))\n",
    "print ('Kriging')\n",
    "print (stats.mode(Krig_Fun_RR) , np.std(Krig_Fun_RR))\n",
    "print ('SVM')\n",
    "print (stats.mode(SVM_Fun_RR) , np.std(SVM_Fun_RR))\n",
    "print ('RBFN')\n",
    "print (stats.mode(RBFN_Fun_RR) , np.std(RBFN_Fun_RR))\n",
    "print ('KNN')\n",
    "print (stats.mode(KNN_Fun_RR) , np.std(KNN_Fun_RR))\n",
    "print ('RF')\n",
    "print (stats.mode(RF_Fun_RR) , np.std(RF_Fun_RR))\n",
    "print ('ELN')\n",
    "print (stats.mode(ELN_Fun_RR) , np.std(ELN_Fun_RR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bench_Fun_RC = np.zeros(100)\n",
    "Krig_Fun_RC = np.zeros(100)\n",
    "SVM_Fun_RC = np.zeros(100)\n",
    "RBFN_Fun_RC = np.zeros(100)\n",
    "KNN_Fun_RC = np.zeros(100)\n",
    "RF_Fun_RC = np.zeros(100)\n",
    "ELN_Fun_RC = np.zeros(100)\n",
    "for i in range(X_Values_RC.shape[0]):\n",
    "    Bench_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,:2])\n",
    "    Krig_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,2:4])\n",
    "    SVM_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,4:6])\n",
    "    RBFN_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,6:8])\n",
    "    KNN_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,8:10])\n",
    "    RF_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,10:12])\n",
    "    ELN_Fun_RC [i] = composite_robustness(X_Values_RC.iloc[i,12:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLSQP\n",
      "ModeResult(mode=array([0.57358994]), count=array([1])) 0.1713733936429688\n",
      "Kriging\n",
      "ModeResult(mode=array([1.39092599]), count=array([1])) 52.02764455084981\n",
      "SVM\n",
      "ModeResult(mode=array([3.18506436]), count=array([1])) 6.940028448290786\n",
      "RBFN\n",
      "ModeResult(mode=array([1.34171041]), count=array([1])) 51.41937643033686\n",
      "KNN\n",
      "ModeResult(mode=array([1.50876349]), count=array([1])) 42.873348759793934\n",
      "RF\n",
      "ModeResult(mode=array([1.50877233]), count=array([1])) 52.317147212648294\n",
      "ELN\n",
      "ModeResult(mode=array([11.66358796]), count=array([45])) 1.0441285005381706e-10\n"
     ]
    }
   ],
   "source": [
    "print ('SLSQP')\n",
    "print (stats.mode(Bench_Fun_RC) , np.std(Bench_Fun_RC))\n",
    "print ('Kriging')\n",
    "print (stats.mode(Krig_Fun_RC) , np.std(Krig_Fun_RC))\n",
    "print ('SVM')\n",
    "print (stats.mode(SVM_Fun_RC) , np.std(SVM_Fun_RC))\n",
    "print ('RBFN')\n",
    "print (stats.mode(RBFN_Fun_RC) , np.std(RBFN_Fun_RC))\n",
    "print ('KNN')\n",
    "print (stats.mode(KNN_Fun_RC) , np.std(KNN_Fun_RC))\n",
    "print ('RF')\n",
    "print (stats.mode(RF_Fun_RC) , np.std(RF_Fun_RC))\n",
    "print ('ELN')\n",
    "print (stats.mode(ELN_Fun_RC) , np.std(ELN_Fun_RC))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
