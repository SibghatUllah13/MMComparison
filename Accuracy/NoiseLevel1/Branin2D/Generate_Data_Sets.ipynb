{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyDOE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Utils \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import namedtuple\n",
    "from matplotlib import cm\n",
    "import cma\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValueRange = namedtuple('ValueRange', ['min', 'max'])\n",
    "\n",
    "def determinerange(values):\n",
    "    \"\"\"Determine the range of values in each dimension\"\"\"\n",
    "    return ValueRange(np.min(values, axis=0), np.max(values, axis=0))\n",
    "\n",
    "\n",
    "def linearscaletransform(values, *, range_in=None, range_out=ValueRange(0, 1), scale_only=False):\n",
    "    \"\"\"Perform a scale transformation of `values`: [range_in] --> [range_out]\"\"\"\n",
    "\n",
    "    if range_in is None:\n",
    "        range_in = determinerange(values)\n",
    "    elif not isinstance(range_in, ValueRange):\n",
    "        range_in = ValueRange(*range_in)\n",
    "\n",
    "    if not isinstance(range_out, ValueRange):\n",
    "        range_out = ValueRange(*range_out)\n",
    "\n",
    "    scale_out = range_out.max - range_out.min\n",
    "    scale_in = range_in.max - range_in.min\n",
    "\n",
    "    if scale_only:\n",
    "        scaled_values = (values / scale_in) * scale_out\n",
    "    else:\n",
    "        scaled_values = (values - range_in.min) / scale_in\n",
    "        scaled_values = (scaled_values * scale_out) + range_out.min\n",
    "\n",
    "    return scaled_values\n",
    "\n",
    "\n",
    "''' Plot the Graph of the Function'''\n",
    "def plot_the_graph(x,y,z,graph_title):\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    ax = Axes3D(fig)\n",
    "    surf = ax.plot_trisurf(x,y,z,cmap=cm.jet, linewidth=0.3,alpha=0.9)\n",
    "    fig.colorbar(surf, shrink=10, aspect=3)\n",
    "    ax.set_xlabel('X1')\n",
    "    ax.set_ylabel('X2')\n",
    "    ax.set_zlabel('Robust(X1,X2)')\n",
    "    plt.title(graph_title)\n",
    "    plt.show()\n",
    "    fig.savefig(graph_title+'.pdf')\n",
    "\n",
    "''' Branin Test Example  '''\n",
    "def branin_test_example(X):\n",
    "    x,z = X\n",
    "    A = (z) - ((5.1) / (4 * np.square(np.pi))) * (x **2) + (( (5)/(np.pi) ) * (x) ) - (6)\n",
    "    B = (10 * ((1) - ((1) / (8 * np.pi) )) ) * (np.cos(x))\n",
    "    return np.square(A) + B + 10\n",
    "\n",
    "\n",
    "''' Latin HyperCube Sampling Design of Experiment '''\n",
    "def DOE(n_obs):\n",
    "    np.random.seed(0)\n",
    "    lhd = pyDOE.lhs(n=2, samples=n_obs, criterion='m')\n",
    "    X1, X2 = lhd[:,0], lhd[:,1]\n",
    "    return X1,X2\n",
    "\n",
    "\n",
    "'''Robust Regularization based on minimax Principle 5% perturbations'''\n",
    "def robust_regularization(X):\n",
    "    x1,x2 = X\n",
    "    eps = np.linspace(-0.75,0.75,1000)\n",
    "    return np.max( branin_test_example([x1+eps,x2+eps]) )\n",
    "\n",
    "''' Robustness based on a composite function of Mean and STd '''\n",
    "def composite_robustness(X):\n",
    "    w=1\n",
    "    x1,x2 = X\n",
    "    np.random.seed(0)\n",
    "    eps = np.random.normal(loc=0.0,scale=0.125,size=10000)\n",
    "    sample_points = branin_test_example([x1+eps,x2+eps])\n",
    "    sample_mean = np.mean(sample_points)\n",
    "    variance = np.square(sample_points-sample_mean)\n",
    "    std = np.sqrt(np.mean(variance))\n",
    "    std = np.sqrt(np.mean(variance))\n",
    "    return sample_mean + w * std\n",
    "\n",
    "''' Generate Training Data using LHD along side the Output of the Robust System'''\n",
    "def generate_training_data(n_obs):\n",
    "    X1,X2 = DOE(n_obs)\n",
    "    X1 = linearscaletransform(X1,range_out=(-5,10))\n",
    "    X2 = linearscaletransform(X2,range_out=(0,15))\n",
    "    f_evaluation = branin_test_example([X1,X2])\n",
    "    f_original = np.zeros(X1.shape[0])\n",
    "    minimax_original = np.zeros(X1.shape[0])\n",
    "    composite_original = np.zeros(X1.shape[0])\n",
    "    for i in range(X1.shape[0]):\n",
    "        f_original[i] = branin_test_example([X1[i],X2[i]])\n",
    "        minimax_original[i] = robust_regularization([X1[i],X2[i]])\n",
    "        composite_original[i] = composite_robustness([X1[i],X2[i]])\n",
    "    train = pd.DataFrame()\n",
    "    train['X1'] = pd.Series(X1)\n",
    "    train['X2'] = pd.Series(X2)\n",
    "    train['Y = F(X1,X2)'] = pd.Series(f_original)\n",
    "    train['Y = robust_regularization(X1,X2)'] = pd.Series(minimax_original)\n",
    "    train['Y = composite(X1,X2)'] = pd.Series(composite_original)\n",
    "    train.to_csv('Training_Data_Sets\\\\'+str(n_obs)+'Samples.csv')\n",
    "    return train\n",
    "\n",
    "''' Generate Test Data using LHD along side the Output of the Robust System'''\n",
    "def generate_test_data(n_obs):\n",
    "    test = pd.DataFrame()\n",
    "    np.random.seed(0)\n",
    "    lhd = pyDOE.lhs(n=2, samples=n_obs, criterion='m')\n",
    "    X1 = linearscaletransform(lhd[:,0],range_out=(-5,10))\n",
    "    X2 = linearscaletransform(lhd[:,1],range_out=(0,15))\n",
    "    test ['X1'] = pd.Series(X1)\n",
    "    test ['X2'] = pd.Series(X2)\n",
    "    true_minimax = np.zeros(test.shape[0])\n",
    "    true_composite = np.zeros(test.shape[0])\n",
    "    for i in range(test.shape[0]):\n",
    "        true_minimax[i] = robust_regularization(test.iloc[i,:])\n",
    "        true_composite[i] = composite_robustness(test.iloc[i,:])\n",
    "    test ['True_Minimax'] = pd.Series(true_minimax)\n",
    "    test ['True_Composite'] = pd.Series(true_composite)\n",
    "    test.to_csv('Test_Data_Sets\\\\'+str(n_obs)+'Samples.csv')\n",
    "    return test\n",
    "\n",
    "''' Check if There are same examples in Test and Train Data Sets'''\n",
    "def check_data_sets(train,test):\n",
    "    C = train.isin(test)\n",
    "    C = pd.DataFrame.sum(C,axis=1)\n",
    "    ids = C.index[C>1]\n",
    "    print ('Total Number of Input Observations present in Test Data : '+str(ids.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMA-ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3_w,6)-aCMA-ES (mu_w=2.0,w_1=63%) in dimension 2 (seed=242281, Mon Apr  1 14:47:37 2019)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1      6 7.362740929427954e+00 1.0e+00 3.37e+00  3e+00  3e+00 0:00.0\n",
      "    2     12 1.550521970811233e+01 1.1e+00 3.39e+00  3e+00  3e+00 0:00.1\n",
      "    3     18 1.422170022637720e+01 1.2e+00 2.63e+00  2e+00  2e+00 0:00.1\n",
      "  100    600 4.749218739824405e+00 9.3e+04 3.94e-05  1e-06  3e-06 0:00.3\n",
      "  131    786 4.749218739731116e+00 3.9e+06 2.62e-06  4e-08  1e-07 0:00.4\n",
      "termination on tolfun=1e-11 (Mon Apr  1 14:47:38 2019)\n",
      "final/bestever f-value = 4.749219e+00 4.749219e+00\n",
      "incumbent solution: [3.168458730867274, 2.2606938052869348]\n",
      "std deviation: [3.903666963926408e-08, 1.2658935445260423e-07]\n",
      "(3_w,6)-aCMA-ES (mu_w=2.0,w_1=63%) in dimension 2 (seed=211317, Mon Apr  1 14:47:38 2019)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1      6 1.351437135529600e+00 1.0e+00 4.24e+00  4e+00  5e+00 0:00.0\n",
      "    2     12 1.245911461847355e+01 1.6e+00 4.35e+00  4e+00  4e+00 0:00.0\n",
      "    3     18 5.176411932250522e+01 1.2e+00 4.09e+00  3e+00  4e+00 0:00.0\n",
      "  100    600 8.439288999134135e+00 1.1e+02 2.82e-06  1e-08  3e-08 0:00.8\n",
      "  136    816 8.439288999949428e+00 8.0e+02 6.19e-09  4e-12  9e-12 0:01.1\n",
      "termination on tolx=1e-11 (Mon Apr  1 14:47:40 2019)\n",
      "termination on tolfun=1e-11 (Mon Apr  1 14:47:40 2019)\n",
      "final/bestever f-value = 8.439289e+00 1.351437e+00\n",
      "incumbent solution: [8.924968098226323, -0.3704353857813]\n",
      "std deviation: [9.293879743685222e-12, 4.104507551919839e-12]\n"
     ]
    }
   ],
   "source": [
    "opt = {'seed': 0 , 'maxfevals': 1e6  }\n",
    "rr = cma.fmin(robust_regularization, 2 * [0] , sigma0= 3.75 , options=opt  )\n",
    "rc = cma.fmin(composite_robustness, 2 * [0] , 3.75 , options=opt  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xmin for RR :[3.16845874 2.26069378]\n",
      "Fmin for RR :4.749218739730794\n",
      "Xmin for RC :[3.04923578 3.07476018]\n",
      "Fmin for RC :1.3514371355295995\n"
     ]
    }
   ],
   "source": [
    "print ('Xmin for RR :'+str(rr[0]))\n",
    "print ('Fmin for RR :'+str(rr[1]))\n",
    "print ('Xmin for RC :'+str(rc[0]))\n",
    "print ('Fmin for RC :'+str(rc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLSQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "const = Bounds([-5, 0], [10, 15])\n",
    "min_robust = minimize(robust_regularization,(0,0),method='SLSQP',bounds=const)\n",
    "min_compo = minimize(composite_robustness,(0,0),method='SLSQP',bounds=const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 4.74921897813906\n",
       "     jac: array([8.19556093, 2.52639109])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 61\n",
       "     nit: 11\n",
       "    njev: 11\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([3.16860056, 2.26023388])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.6885919120360248\n",
       "     jac: array([0.00283798, 0.00157474])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 31\n",
       "     nit: 7\n",
       "    njev: 7\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([3.14540113, 2.27765575])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_compo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "lhd = pyDOE.lhs(n=2, samples= 1000, criterion='m')\n",
    "X1 = linearscaletransform(lhd[:,0],range_out=(-5,10))\n",
    "X2 = linearscaletransform(lhd[:,1],range_out=(0,15))\n",
    "Data = pd.DataFrame()\n",
    "Data['X1'] = pd.Series(X1)\n",
    "Data['X2'] = pd.Series(X2)\n",
    "Data.to_csv('Optimization_Test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(sys.path[1]+str('\\\\Training_Data_Sets\\\\100Samples.csv')).iloc[:,1:]\n",
    "test = pd.read_csv('Optimization_Test.csv').iloc[:,1:]\n",
    "model_k_m,pred_k_m = Utils.kriging_minimax(train,test.iloc[:,:2])\n",
    "model_k_c,pred_k_c, predict_k_c = Utils.kriging_composite(train,test.iloc[:,:2])\n",
    "model_r_m,pred_r_m = Utils.rf_minimax(train,test.iloc[:,:2])\n",
    "model_r_c,pred_r_c = Utils.rf_composite(train,test.iloc[:,:2])\n",
    "model_n_m,pred_n_m = Utils.KNN_minimax(train,test.iloc[:,:2])\n",
    "model_n_c,pred_n_c = Utils.KNN_composite(train,test.iloc[:,:2])\n",
    "model_s_m,pred_s_m = Utils.SVR_minimax(train,test.iloc[:,:2])\n",
    "model_s_c,pred_s_c = Utils.SVR_composite(train,test.iloc[:,:2])\n",
    "model_b_m,pred_b_m = Utils.RBF_minimax(train,test.iloc[:,:2])\n",
    "model_b_c,pred_b_c = Utils.RBF_composite(train,test.iloc[:,:2])\n",
    "train ['X1X2'] = pd.Series( np.array(train.X1) * np.array(train.X2) )\n",
    "train ['X1**2'] = pd.Series ( np.array(train.X1)**2 )\n",
    "train ['X2**2'] = pd.Series ( np.array(train.X2)**2 )\n",
    "f_original = train['Y = F(X1,X2)']\n",
    "robust_original = train['Y = robust_regularization(X1,X2)']\n",
    "composite_original = train ['Y = composite(X1,X2)']\n",
    "del train['Y = F(X1,X2)']\n",
    "del train['Y = robust_regularization(X1,X2)']\n",
    "del train ['Y = composite(X1,X2)']\n",
    "train['Y = F(X1,X2)'] = f_original\n",
    "train['Y = robust_regularization(X1,X2)'] = robust_original\n",
    "train ['Y = composite(X1,X2)'] = composite_original\n",
    "test ['X1X2'] =  pd.Series( np.array(test.X1) * np.array(test.X2) )\n",
    "test ['X1**2'] = pd.Series ( np.array(test.X1)**2 )\n",
    "test ['X2**2'] = pd.Series ( np.array(test.X2)**2 )\n",
    "model_m_m,pred_m_m = Utils.elastic_net_minimax(train,test.iloc[:,:5])\n",
    "model_m_c,pred_m_c = Utils.elastic_net_composite(train,test.iloc[:,:5])\n",
    "del train['X1X2']\n",
    "del train['X1**2']\n",
    "del train['X2**2']\n",
    "del test['X1X2']\n",
    "del test['X1**2']\n",
    "del test['X2**2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using Kriging is : 3.4806892983928064\n",
      "At X = :[9.36959876 2.26244102]\n",
      "RC :  Minimum Using Kriging is : 0.6419251048636476\n",
      "At X = :[9.36959876 2.26244102]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using Kriging is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_k_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_k_m),:])))\n",
    "print ('RC :  Minimum Using Kriging is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_k_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_k_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using SVR  is : 3.4806892983928064\n",
      "At X = :[9.36959876 2.26244102]\n",
      "RC :  Minimum Using SVR is : 0.6419251048636476\n",
      "At X = :[9.36959876 2.26244102]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using SVR  is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_s_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_s_m),:])))\n",
    "print ('RC :  Minimum Using SVR is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_s_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_s_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using KNN is : 4.612088943081217\n",
      "At X = :[9.63251943 3.02129638]\n",
      "RC :  Minimum Using KNN is : 1.072724247575367\n",
      "At X = :[9.63251943 3.02129638]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using KNN is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_n_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_n_m),:])))\n",
    "print ('RC :  Minimum Using KNN is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_n_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_n_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using RF is : 8.607094779491826\n",
      "At X = :[3.80016646 0.28539309]\n",
      "RC :  Minimum Using RF is : 1.8708284689112409\n",
      "At X = :[-3.35296076 12.30502167]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using RF is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_r_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_r_m),:])))\n",
    "print ('RC :  Minimum Using RF is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_r_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_r_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using RBFN is : 21.762172787612897\n",
      "At X = :[-0.60665265  6.52735601]\n",
      "RC :  Minimum Using RBFN is : 5.714378689086536\n",
      "At X = :[-4.1052656  14.85397582]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using RBFN is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_b_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_b_m),:])))\n",
    "print ('RC :  Minimum Using RBFN is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_b_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_b_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR :  Minimum Using ELN is : 11.807694047907475\n",
      "At X = :[9.68565187 0.08147672]\n",
      "RC :  Minimum Using ELN is : 7.945527364207643\n",
      "At X = :[9.68565187 0.08147672]\n"
     ]
    }
   ],
   "source": [
    "print ('RR :  Minimum Using ELN is : '+str ( robust_regularization(np.array(test.iloc[np.argmin(pred_m_m),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_m_m),:])))\n",
    "print ('RC :  Minimum Using ELN is : '+str ( composite_robustness(np.array(test.iloc[np.argmin(pred_m_c),:]))))\n",
    "print ('At X = :'+str(np.array(test.iloc[np.argmin(pred_m_c),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1067.6470588235293"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(7.94-0.68)/(0.68) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-c0d663a6c966>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_k_c\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_k_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_k_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUtils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkriging_composite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "model_k_c,pred_k_c, predict_k_c = Utils.kriging_composite(train,test.iloc[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 26.169225729989556\n",
       "     jac: array([0., 0.])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 4\n",
       "     nit: 1\n",
       "    njev: 1\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([3., 3.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(func,(3,3),method='SLSQP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
