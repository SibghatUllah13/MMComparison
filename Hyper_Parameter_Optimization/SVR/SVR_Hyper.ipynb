{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Utils\n",
    "import pyDOE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats.distributions as dist\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from collections import namedtuple\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Support Vector Regression for Robust Regularization'''\n",
    "def SVR_minimax(train_data,test_data,Hyper):\n",
    "    gam, reg= Hyper\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:10].values, test_data.values])\n",
    "    gpr = SVR(gamma=gam ,C=reg, epsilon=0.25,max_iter=1500).fit(\n",
    "        scaler.transform(train_data.iloc[:,:10]), train_data.iloc[:,11])\n",
    "    pred = gpr.predict(scaler.transform(test_data))\n",
    "    return gpr,pred\n",
    "\n",
    "''' Support Vector Regression for Robust Composition'''\n",
    "def SVR_composite(train_data,test_data,Hyper):\n",
    "    gam, reg = Hyper\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:10].values, test_data.values])\n",
    "    gpr = SVR(gamma=gam,  C=reg, epsilon=0.2\n",
    "             ).fit(scaler.transform(train_data.iloc[:,:10]), train_data.iloc[:,-1])\n",
    "    pred = gpr.predict(scaler.transform(test_data))\n",
    "    return gpr,pred\n",
    "\n",
    "\n",
    "''' Latin HyperCube Sampling Design of Experiment for Hyper_Parameters Optimization'''\n",
    "def DOE_Hyper():\n",
    "    lhd = pyDOE.lhs(n=2, samples=1500, criterion='m')\n",
    "    X1, X2 = lhd[:,0], lhd[:,1] \n",
    "    X1 = Utils.linearscaletransform(X1,range_out=(0.00001,1e2))\n",
    "    X2 = Utils.linearscaletransform(X2,range_out=(0.0001 , 1000))\n",
    "    Hyper_Parameters = pd.DataFrame()\n",
    "    Hyper_Parameters['Gamma'] = pd.Series(X1)\n",
    "    Hyper_Parameters['Regularization'] = pd.Series(X2)\n",
    "    return Hyper_Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training and Test Data Set initially Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(sys.path[1][:-4]+str('\\\\Training_Data_Sets\\\\50Samples.csv')).iloc[:,1:]\n",
    "test = pd.read_csv(sys.path[1][:-4]+str('\\\\Test_Data_Sets\\\\750Samples.csv')).iloc[:,1:]\n",
    "true_minimax = np.array(test.True_Minimax)\n",
    "true_composite = np.array(test.True_Composite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [50,100,150,200,250,300,350,400,450,500]\n",
    "Kriging_minimax = np.zeros([len(X),2])\n",
    "Kriging_composite = np.zeros([len(X),2])\n",
    "for k in range(len(X)):\n",
    "    print (X[k])\n",
    "    train = pd.read_csv(sys.path[1][:-4]+str('\\\\Training_Data_Sets\\\\'+str(X[k])+'Samples.csv')).iloc[:,1:]\n",
    "    test = pd.read_csv(sys.path[1][:-4]+str('\\\\Test_Data_Sets\\\\750Samples.csv')).iloc[:,1:]\n",
    "    true_minimax = np.array(test.True_Minimax)\n",
    "    true_composite = np.array(test.True_Composite)\n",
    "    Hyper_Parameters = DOE_Hyper()\n",
    "    mean_abs_error_minimax = np.zeros(Hyper_Parameters.shape[0])\n",
    "    mean_abs_error_composite = np.zeros(Hyper_Parameters.shape[0])\n",
    "    for i in range(Hyper_Parameters.shape[0]):\n",
    "        temp = np.array(Hyper_Parameters.iloc[i,:])\n",
    "        model_minimax,pred_k_m = SVR_minimax(train,test.iloc[:,:10],temp)\n",
    "        model_composite,pred_k_c = SVR_composite(train,test.iloc[:,:10],temp)\n",
    "        mean_abs_error_minimax[i] = np.mean((abs(true_minimax-pred_k_m) / abs(true_minimax) ) * 100)\n",
    "        mean_abs_error_composite[i] = np.mean((abs( true_composite-pred_k_c) / abs(true_composite) ) * 100)\n",
    "    Hyper_Parameters ['Mean_Error_Minimax'] = pd.Series(mean_abs_error_minimax)\n",
    "    Hyper_Parameters ['Mean_Error_Composite'] = pd.Series(mean_abs_error_composite)\n",
    "    Kriging_minimax [k,:] = np.array(Hyper_Parameters.iloc[Hyper_Parameters.Mean_Error_Minimax.values.argmin(),:-2])\n",
    "    Kriging_composite [k,:] = np.array(Hyper_Parameters.iloc[Hyper_Parameters.Mean_Error_Composite.values.argmin(),:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Configuration of Hyper Parameters for Robust Regularization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gamma                   0.085344\n",
       "Regularization        703.315585\n",
       "Mean_Error_Minimax      1.786918\n",
       "Name: 558, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Best Configuration of Hyper Parameters for Robust Regularization')\n",
    "Hyper_Parameters.iloc[Hyper_Parameters.Mean_Error_Minimax.values.argmin(),:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Configuration of Hyper Parameters for Robust Regularization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gamma                     0.085344\n",
       "Regularization          703.315585\n",
       "Mean_Error_Composite      0.764393\n",
       "Name: 558, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Best Configuration of Hyper Parameters for Robust Regularization')\n",
    "Hyper_Parameters.iloc[Hyper_Parameters.Mean_Error_Composite.values.argmin(),[0,1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hyper_Parameters.to_csv('Result_Hyper_Params.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Kriging_composite).to_csv('composite.csv')\n",
    "pd.DataFrame(Kriging_minimax).to_csv('minimax.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimax = pd.read_csv('minimax.csv').iloc[:,1:]\n",
    "composite = pd.read_csv('composite.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.12253184e-01, 6.09347260e+02],\n",
       "       [3.28014021e-01, 4.19498608e+02],\n",
       "       [2.39611321e-01, 4.59765582e+02],\n",
       "       [2.06132759e-01, 5.44014106e+02],\n",
       "       [1.07259239e-01, 6.81120508e+02],\n",
       "       [2.07004671e-01, 4.98124611e+02],\n",
       "       [1.86361488e-01, 5.90693615e+02],\n",
       "       [1.38763994e-01, 6.08545310e+02],\n",
       "       [9.64341034e-02, 5.40008587e+02],\n",
       "       [8.53443233e-02, 7.03315585e+02]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(composite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.94985993e-01, 1.65813533e+02],\n",
       "       [4.74862477e-01, 1.86038992e+02],\n",
       "       [1.37755283e-01, 3.66997650e+02],\n",
       "       [1.32896676e-01, 2.42166170e+02],\n",
       "       [1.70287434e-01, 1.79163720e+02],\n",
       "       [2.07004671e-01, 4.98124611e+02],\n",
       "       [9.89057033e-02, 9.41770798e+02],\n",
       "       [8.26062363e-02, 7.28446785e+02],\n",
       "       [9.64341034e-02, 5.40008587e+02],\n",
       "       [8.53443233e-02, 7.03315585e+02]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(minimax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
