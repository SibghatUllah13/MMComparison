{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\sefi\\\\Meta-Modelling\\\\Sample Size vs Accuracy\\\\Noise Level 3\\\\Rastrigin10D\\\\\")\n",
    "import Utils\n",
    "import pyDOE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from RBFN import RBFN\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' RBF Network Interpolation for Robust Regularization'''\n",
    "def RBF_minimax(train_data,test_data,Hyper):\n",
    "    shape,sig = Hyper\n",
    "    model = RBFN(hidden_shape=int(shape), sigma=sig)\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:10].values, test_data.values])\n",
    "    model.fit(scaler.transform(np.array(train_data.iloc[:,:10])), np.array(train_data.iloc[:,11]))\n",
    "    pred = model.predict(scaler.transform(np.array(test_data)))\n",
    "    return model,pred\n",
    "\n",
    "''' RBF Network Interpolation for Robust Composition'''\n",
    "def RBF_composite(train_data,test_data,Hyper):\n",
    "    shape,sig = Hyper\n",
    "    model = RBFN(hidden_shape=int(shape), sigma=sig)\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:10].values, test_data.values])\n",
    "    model.fit(scaler.transform(np.array(train_data.iloc[:,:10])), np.array(train_data.iloc[:,-1]))\n",
    "    pred = model.predict(scaler.transform(np.array(test_data)))\n",
    "    return model,pred\n",
    "\n",
    "''' Latin HyperCube Sampling Design of Experiment for Hyper_Parameters Optimization'''\n",
    "def DOE_Hyper():\n",
    "    lhd = pyDOE.lhs(n=2, samples=500, criterion='m')\n",
    "    X1, X2  = lhd[:,0], lhd[:,1] \n",
    "    X1 = Utils.linearscaletransform(X1,range_out=(5,1e2))\n",
    "    X2 = Utils.linearscaletransform(X2,range_out=(1e-3 , 1e3))\n",
    "    Hyper_Parameters = pd.DataFrame()\n",
    "    Hyper_Parameters['Shape'] = pd.Series(X1)\n",
    "    Hyper_Parameters['Sigma'] = pd.Series(X2)\n",
    "    return Hyper_Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training and Test Data Set initially Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12,17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "X = [50,100,150,200,250,300,350,400,450,500]\n",
    "Kriging_minimax = np.zeros([len(X),2])\n",
    "Kriging_composite = np.zeros([len(X),2])\n",
    "for k in range(len(X)):\n",
    "    print (X[k])\n",
    "    train = pd.read_csv(sys.path[1][:-4]+str('Training_Data_Sets\\\\'+str(X[k])+'Samples.csv')).iloc[:,1:]\n",
    "    test = pd.read_csv(sys.path[1][:-4]+str('Test_Data_Sets\\\\750Samples.csv')).iloc[:,1:]\n",
    "    true_minimax = np.array(test.True_Minimax)\n",
    "    true_composite = np.array(test.True_Composite)\n",
    "    Hyper_Parameters = DOE_Hyper()\n",
    "    mean_abs_error_minimax = np.zeros(Hyper_Parameters.shape[0])\n",
    "    mean_abs_error_composite = np.zeros(Hyper_Parameters.shape[0])\n",
    "    for i in range(Hyper_Parameters.shape[0]):\n",
    "        temp = np.array(Hyper_Parameters.iloc[i,:])\n",
    "        model_minimax,pred_k_m = RBF_minimax(train,test.iloc[:,:10],temp)\n",
    "        model_composite,pred_k_c = RBF_composite(train,test.iloc[:,:10],temp)\n",
    "        mean_abs_error_minimax[i] = np.mean((abs(true_minimax-pred_k_m) / abs(true_minimax) ) * 100)\n",
    "        mean_abs_error_composite[i] = np.mean((abs( true_composite-pred_k_c) / abs(true_composite) ) * 100)\n",
    "    Hyper_Parameters ['Mean_Error_Minimax'] = pd.Series(mean_abs_error_minimax)\n",
    "    Hyper_Parameters ['Mean_Error_Composite'] = pd.Series(mean_abs_error_composite)\n",
    "    Kriging_minimax [k,:] = np.array(Hyper_Parameters.iloc[Hyper_Parameters.Mean_Error_Minimax.values.argmin(),:-2])\n",
    "    Kriging_composite [k,:] = np.array(Hyper_Parameters.iloc[Hyper_Parameters.Mean_Error_Composite.values.argmin(),:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Configuration of Hyper Parameters for Robust Regularization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Shape                 90.059425\n",
       "Sigma                  0.001000\n",
       "Mean_Error_Minimax     1.849618\n",
       "Name: 313, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Best Configuration of Hyper Parameters for Robust Regularization')\n",
    "Hyper_Parameters.iloc[Hyper_Parameters.Mean_Error_Minimax.values.argmin(),:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Configuration of Hyper Parameters for Robust Composition\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Shape                   90.059425\n",
       "Sigma                    0.001000\n",
       "Mean_Error_Composite     0.732452\n",
       "Name: 313, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Best Configuration of Hyper Parameters for Robust Composition')\n",
    "Hyper_Parameters.iloc[Hyper_Parameters.Mean_Error_Composite.values.argmin(),[0,1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hyper_Parameters.to_csv('Result_Hyper_Params.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Kriging_composite).to_csv('composite.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Kriging_composite).to_csv('composite.csv')\n",
    "pd.DataFrame(Kriging_minimax).to_csv('minimax.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimax = pd.read_csv('minimax.csv').iloc[:,1:]\n",
    "composite = pd.read_csv('composite.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.09282034e+01, 1.00000000e-03],\n",
       "       [7.96230039e+01, 1.00000000e-03],\n",
       "       [4.56638968e+01, 1.00000000e-03],\n",
       "       [9.42536820e+01, 1.00000000e-03],\n",
       "       [7.15406807e+01, 1.00000000e-03],\n",
       "       [7.32351977e+01, 1.00000000e-03],\n",
       "       [6.87084920e+01, 1.00000000e-03],\n",
       "       [8.21848068e+01, 1.00000000e-03],\n",
       "       [2.82565359e+01, 1.00000000e-03],\n",
       "       [9.00594246e+01, 1.00000000e-03]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(minimax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.09282034e+01, 1.00000000e-03],\n",
       "       [7.96230039e+01, 1.00000000e-03],\n",
       "       [4.56638968e+01, 1.00000000e-03],\n",
       "       [9.42536820e+01, 1.00000000e-03],\n",
       "       [7.15406807e+01, 1.00000000e-03],\n",
       "       [7.32351977e+01, 1.00000000e-03],\n",
       "       [6.87084920e+01, 1.00000000e-03],\n",
       "       [8.21848068e+01, 1.00000000e-03],\n",
       "       [2.82565359e+01, 1.00000000e-03],\n",
       "       [9.00594246e+01, 1.00000000e-03]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(composite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
